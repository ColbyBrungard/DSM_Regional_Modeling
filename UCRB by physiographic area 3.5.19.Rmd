---
title: "UCRB Modeling SoilDepth"
author: "cbrungard"
date: "August 24, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyr)
library(caret)
library(ranger)
library(sp)
library(doParallel)
library(forcats)
library(plyr)
```

1. Load observations and split into training and evaluation sets. 
```{r, include=FALSE}
# Read in regression matrix
obs <- read.csv("Z:/UCRB/Observations/regMatrix_2.15.19.csv")

#Force depth classes to be an ordered factor
obs$DepthClass <- factor(obs$DepthClass, levels = c('BR', 'VS', 'S', 'MD', 'D', 'VD'))

# I originally included lat/long as predictors. I am glad that I did this because they came out as important predictors which revealed that the clustering of data did have an impact, but including lat/long as covariates produces spurious spatial patterns in the predictions (they are often among the most important predictors). When I remove them accuracy drops ~ 3%, but remove them. Does this suggest that I should use regression kriging for continious attributes?

# Also remove GAP and NLCDcl factors because there are 93 levels of GAP (too many levels for RF) and NLCDcl classes 0 and 128 are never observed in the data. Also remove US_L4Name (EPA ecoregion IV), because it has too many levels

# After some thought, I also decided to exclude the standard deviation of the Landsat band ratios: 5/7, 5/4, and 5/1. While these were somewhat (not very) important predictors I can't explain them. The median values are intended to capture spatial variations in minerology/geology, but are obviously influenced by vegetation. Since I am including variability in NDVI (4/3) I feel that this captures vegetation variability and this I can explain. Interestlingly, when I remove these std deviations variables the model accuray and kappa both increase by 2-3%.

# The predictions had holes because of holes in the radar or imagery in areas of deep cliff or canyon. I've got enough observations that it is easiest to just drop these for now. My other option would be to fill the 'holes' in the the raster using inverse distance weighting (rfillspgaps in the meteo package), but I tried this and maxed out 32 GB memory (could probably do this with 64 GB Ram). I'm just going to remove these observations. After running the models without radar imagery I find that the accuracy drops ~ 0.5 to 1% (for both CV and independent validation). I think that this is justified as dropping the radar imagery means that I don't have big holes in the predictions. 

# Several variables were duplicated between what Travis and I calculated including: profile curvature tangential curvature, catchment area, and slope. Remove these duplicated variables; use those that I created as I am more familiar with them. 

# Also remove SiteID and depth (in cm) from the data
obs2 <- subset(obs, select=-c(SiteID,Depth,GAP,NLCDcl_m,L51_std_m,L54_std_m,L57_std_m,vv_med_m,vv_std_m,TCURV_rs_m,SLOPE_rs_m,PCURV_rs_m,CAlog_10_rs_m))

# Remove missing depth class values
obs3 <- drop_na(obs2)

# Reorder the data frame to put all land class variables at the begining. This just makes indexing easier. 
obs3 <- obs3[c(1:6,44,7:43,45:71)]

# Combine regions that only have a few observations (doing this here avoids trouble with accidently adding predictor columns, but I didn't figure this out until I tried modeling by region).
# MLRA 
# How many observations by mlra?
obs3$mlra_UCRB_m <- as.factor(obs3$mlra_UCRB_m)
table(obs3$mlra_UCRB_m)
# mlra id's 35:38, 51, 66 have < 200 points (all others have > ~ 400 points) and probably need to be merged
# mlra 35: Great Salt Lake Area, 36:Central Nevada Basin and Range, 37:Southern Nevada Basin and Range - combine into one class
# mlra 38: Mojave desert - seperate enough to leave as is, although it only has 204 points
# mlra 51: Arizona and NM mountains has only 122 points, join with colorado plateau
# mlra 66: Southern Rocky mountain parks has only 23 points - join with mlra:Southern Rock Mountains 
obs3$mlra_UCRB_m <- fct_collapse(obs3$mlra_UCRB_m, 
                            '35' = c('35','36','37'), 
                            '45' = c('45', '51'),
                            '65' = c('65','66'))
table(obs3$mlra_UCRB_m)

#Ecoregions
# How many observations by ecoregion?
obs3$us_eco_l3_m <- as.factor(obs3$us_eco_l3_m)
table(obs3$us_eco_l3_m)
# It appears that there are approximately equal numbers of observations by ecoregion (similar enough at least to mlra), that I do not need to combine ecoregions. This is probably because there are fewer, larger ecoregions. However; region 23 (Arizona/Nwe Mexico mountains) has no observations of bedrock so I need to combine this with region 22 (Arizona/New Mexico Plateau) to actually be able to run the model. 
obs3$us_eco_l3_m <- fct_collapse(obs3$us_eco_l3_m, 
                            '22' = c('22','23'))

# Iwahashi Landforms
obs3$iwahashiLF_m <- as.factor(obs3$iwahashiLF_m)
table(obs3$iwahashiLF_m)
# Categories 4, 13, 14, & 15 need to be combined as they have < 200 observations. After further review I decided to group Iwahashi landforms into broader categories by 'overview' groups that have equal overview groupings. Overview groupings are found in the file: legend_iwahasi_et_al_2018.xlsx that are provided with the dataset. These are 1: Bedrock mountain, 2:hills, 3:Large highland slope, 4:Plateau, terrace, large lowland slope, 5:Plain. Even after this grouping I had no bedrock observations in class 5:plain (only about 50 obs, rare class in this area), so I grouped these with class 4, which while not ideal, was the most similar category. 
obs3$iwahashiLF_m <- fct_collapse(obs3$iwahashiLF_m, 
                            "1" = c('1','2','3','4'),    
                            "2" = c('5','6'),    
                            "3" = c('7','8'),    
                            "4" = c('9','10','11','12','13','14','15'))
table(obs3$iwahashiLF_m)



# Split into training and test using the KSSL data and a random subset of 5% each class as validation. 
# Depth class
# Training
t.dc <- obs3[obs3$source != 'KSSL',]
dc.index <- createDataPartition(t.dc$DepthClass, p = 0.95, list = FALSE)
t.dc2 <- t.dc[dc.index, ]
#write.csv(t.dc2, "Z:/UCRB/Observations/t.dc2.csv")
# Remove source, x, and y fields. This makes coding a bit easier, but leaves t.dc2 available for plotting 
t.dc3 <- t.dc2[,-c(2:4)]

#Validation (I may need to think about bedrock since KSSL data has no bedrock observations this effectively 'undersamples' bedrock in the validation data...)
v.dc <- obs3[obs3$source == 'KSSL',]
v.dc2 <- t.dc[-dc.index, ]
v.dc3 <- rbind(v.dc, v.dc2)
#write.csv(v.dc3, "Z:/UCRB/Observations/v.dc3.csv")
# Remove source, x, and y fields. This makes coding a bit easier, but leaves v.dc3 available for plotting 
v.dc4 <- v.dc3[,-c(2:4)]
```

2. Modeling
Set up model tuning parameters that will be used repeatedly. 
Note: I initially used ranger to speed up the model fitting, but abandoned this because I was unable to get class probability predictions from ranger models. I believe this to be because including the argument probability=TRUE makes it impossible for caret to calculate accuracy. Also, ranger didn't seem much faster than random forests.
```{r}
# Set up resampling options: 10 fold cross validation
fitControl <- trainControl(method = "cv", 
                           savePredictions = T, 
                           returnResamp = 'final',
                           allowParallel = TRUE,
                           selectionFunction='oneSE',
                           summaryFunction = multiClassSummary)


# Set a tune grid for manual control of tuning parameters
tunegrid <- expand.grid(mtry=c(2:10,15))

# A function for implementing 'global' model parameters by region. The x[,-2] argument is necessary to remove the categorical land classification variable when fitting the model by region. 
region.train <- function(x) {
  train(DepthClass ~ ., data = x[,-2], method="rf", trControl = fitControl, tuneGrid=tunegrid)
}
```


2.1 Build global depth class model with all variables. 
It is important to use the formula interface with these models, otherwise the predict function throws an error about not matching data types. Super annoying! 
```{r, message=FALSE, warning=FALSE, include=FALSE}
# Register parallel processing
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
M1 = train(DepthClass ~ ., data = t.dc3, method="rf", trControl = fitControl, tuneGrid=tunegrid)
stopCluster(cl)
M1
```


2.1 Build global depth class model not including the categorical land classifications. 
```{r, include=FALSE}
# Set up parallization
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
M2 = train(DepthClass ~ ., data = t.dc3[,-c(2,3,4)], method="rf", trControl = fitControl, tuneGrid=tunegrid)
stopCluster(cl)
M2
```


2.3 Build models by physiographic area
Split the training/testing data by area. 
```{r}
t.mlra <- split(t.dc3[,-c(3,4)], f = t.dc3$mlra_UCRB_m)
t.eco3 <- split(t.dc3[,-c(2,4)], f = t.dc3$us_eco_l3_m)
t.iwlf <- split(t.dc3[,-c(2,3)], f = t.dc3$iwahashiLF_m)
```

2.3.1 MLRA
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
c.mlra <- llply(t.mlra, region.train)
stopCluster(cl)
c.mlra
```

2.3.2 By Ecoregion
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
c.eco3 <- llply(t.eco3, region.train)
stopCluster(cl)
c.eco3
```

2.3.2 By broad landform (iwahashi)
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
c.iwlf <- llply(t.iwlf, region.train)
stopCluster(cl)
c.iwlf
```

Save all models in case things crash
```{r}
#save.image("Z:/UCRB/Models/byPhysiographicArea 3.5.18.Rdata")
```


3. Compare model performance 
3.1 Cross Validation
These plots show that there is more variation in the cross validation when splitting by region than for the global models. This is because there are fewer observations in each region. These plots also show that there are generally some regions higher and some lower than the global model.
```{r}
#mlra
mlra.cv <- resamples(list(global=M1, 
                          global_nlc=M2,
                          mlra_35 = c.mlra[[1]],
                          mlra_38 = c.mlra[[2]],
                          mlra_43 = c.mlra[[3]],
                          mlra_44 = c.mlra[[4]],
                          mlra_45 = c.mlra[[5]],
                          mlra_46 = c.mlra[[6]],
                          mlra_60 = c.mlra[[7]],
                          mlra_64 = c.mlra[[8]],
                          mlra_65 = c.mlra[[9]]))

#ecoregions
eco3.cv <- resamples(list(global= M1, 
                          global_nlc = M2,
                          ecoregion_13 = c.eco3[[1]],
                          ecoregion_14 = c.eco3[[2]],
                          ecoregion_17 = c.eco3[[3]],
                          ecoregion_18 = c.eco3[[4]],
                          ecoregion_19 = c.eco3[[5]],
                          ecoregion_20 = c.eco3[[6]],
                          ecoregion_21 = c.eco3[[7]],
                          ecoregion_22 = c.eco3[[8]]))


#landform
ilf.cv <- resamples(list(global= M1, 
                         global_nlc = M2,
                         Iwahashi_1 = c.iwlf[[1]],
                         Iwahashi_2 = c.iwlf[[2]],
                         Iwahashi_3 = c.iwlf[[3]],
                         Iwahashi_4 = c.iwlf[[4]]))

bwplot(mlra.cv, metric='Accuracy')
bwplot(eco3.cv, metric='Accuracy')
bwplot(ilf.cv, metric='Accuracy')
```


3.2 Independent validation
```{r}
# Global models
# With land classifications
M1.pred <- predict(M1, newdata = v.dc4)
M1.cm <- confusionMatrix(data=M1.pred, reference = v.dc4$DepthClass)

# Without land classifications
M2.pred <- predict(M2, newdata = v.dc4)
M2.cm <- confusionMatrix(data=M2.pred, reference = v.dc4$DepthClass)

# By mlra
mlra.pred <- llply(c.mlra, predict, newdata=v.dc4)
mlra.cm <- list()
for(i in names(mlra.pred)) {
mlra.cm[[i]] <- (confusionMatrix(data=mlra.pred[[i]][v.dc4$mlra_UCRB_m == i], reference=v.dc4[v.dc4$mlra_UCRB_m == i,1]))
}

# Ecoregion
eco3.pred <- llply(c.eco3, predict, newdata=v.dc4)
eco3.cm <- list()
for(i in names(eco3.pred)) {
eco3.cm[[i]] <- (confusionMatrix(data=eco3.pred[[i]][v.dc4$us_eco_l3_m == i], reference=v.dc4[v.dc4$us_eco_l3_m == i,1]))
}

#Landform
ilf.pred <- llply(c.iwlf, predict, newdata=v.dc4)
ilf.cm <- list()
for(i in names(ilf.pred)) {
ilf.cm[[i]] <- (confusionMatrix(data=ilf.pred[[i]][v.dc4$iwahashiLF_m == i], reference=v.dc4[v.dc4$iwahashiLF_m == i,1]))
}

# Get accuracy metrics for each regional model as a dataframe 
mlra.cm.df <- ldply(mlra.cm, "[[", 3)
eco3.cm.df <- ldply(eco3.cm, "[[", 3)
ilf.cm.df  <- ldply(ilf.cm, "[[", 3)

# Add global model values to each data frame
# First create a dataframe that matches the structure I want to join to
gmod <- data.frame('.id' = c('Global', 'Global_nlc'))
gmod1 <- cbind(gmod, rbind(M1.cm$overall, M2.cm$overall))

mlra.acc <- rbind(gmod1, mlra.cm.df) 
eco3.acc <- rbind(gmod1, eco3.cm.df)
ilf.acc <- rbind(gmod1, ilf.cm.df)

# Rename land classes with meaningful names for plotting
library(dplyr)
mlra.acc$.id <- as.character(mlra.acc$.id)
eco3.acc$.id <- as.character(eco3.acc$.id)
ilf.acc$.id <- as.character(ilf.acc$.id)

mlra.acc$.id <- recode(mlra.acc$.id, 
                      `35` = "Great Salt Lake Area",  
                      `38` = "Mojave Desert",
                      `43` = 'Cool Central Desertic Basins and Plateaus',
                      `44` = 'Warm Central Desertic Basins and Plateaus',
                      `45` = 'Colorado Plateau',
                      `46` = 'Southwestern Plateaus, Mesas, and Foothills',
                      `60` = 'Central Rocky Mountains',
                      `64` = 'Wasatch and Uinta Mountains',
                      `65` = 'Southern Rocky Mountains')

eco3.acc$.id <- recode(eco3.acc$.id,
                      `13` =	'Central Basin and Range',
                      `14` =	'Mojave Basin and Range',
                      `17` =	'Middle Rockies',
                      `18` =	'Wyoming Basin',
                      `19` =	'Wasatch and Uinta Mountains',
                      `20` =	'Colorado Plateaus',
                      `21` =	'Southern Rockies',
                      `22` =	'Arizona and New Mexico Plateau')

ilf.acc$.id <- recode(ilf.acc$.id,
                      `1` =	'Bedrock mountain',
                      `2` =	'Hills',
                      `3` =	'Large highland slope',
                      `4` =	'Plateau, terrace, large lowland slope, plains')

# Plot. Note: confusionMatrix calculates accuracyUpper and accuracyLower using a binomial distribution. I dont think this makes sense in a multi-class scenario and 
library(ggplot2)

# Validation accuracy 
# MLRA
mlra.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(size = 2.5) +
  labs(x="MLRA", x = "Accuracy") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationAccuracy_MLRA.png", height=3, width=7)

# Ecoregion
eco3.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(size = 2.5) +
  labs(x="Ecoregion", x = "Accuracy") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationAccuracy_eco3.png", height=3, width=7)

# Landform
ilf.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(size = 2.5) +
  labs(x="Landform", x = "Accuracy") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationAccuracy_iwlf.png", height=3, width=7)
  
 
# Validation Kappa
# Rossiters' "Technical Note: Statistical methods for accuracy assesment of classified thematic maps" indicates that kappa is best when we know the marginal probabilities. We don't know this, so Kappa is not a great estimate of accuracy. Instead, use Tau. 
# MLRA
mlra.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="MLRA", x = "Kappa") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationKappa_MLRA.png", height=3, width=7)

# Ecoregion
eco3.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="Ecoregion", x = "Kappa") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationKappa_eco3.png", height=3, width=7)

# Landform
ilf.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="Landform", x = "Kappa") + 
  coord_flip()
ggsave("Z:/UCRB/Figures/ValidationKappa_iwlf.png", height=3, width=7)

```


3.3. One explanation for differences in model accuracy is that there are more observations in some areas and less in others. 
Is there a relationship between validation accuracy and the number of observations in a region? No there appears to be no relationship between the number of training/validation observations and the accuracy. This leads me to believe that there is another explanation which likely has to do with the inherent pedodiversity or variability of the area.  
```{r}
# Add the number of training and validation observations used to model each region
# MLRA
n.mlra.train <- ddply(t.dc3, .(mlra_UCRB_m), nrow)
n.mlra.val   <- ddply(v.dc4, .(mlra_UCRB_m), nrow)
n.mlra1 <- cbind(n.mlra.train[,-1], n.mlra.val[,-1], mlra.acc[-c(1:2),])
names(n.mlra1)[1] <- 'n_train'
names(n.mlra1)[2] <- 'n_test'

# Ecoregion
n.eco3.train <- ddply(t.dc3, .(us_eco_l3_m), nrow)
n.eco3.val   <- ddply(v.dc4, .(us_eco_l3_m), nrow)
n.eco31 <- cbind(n.eco3.train[,-1], n.eco3.val[,-1], eco3.acc[-c(1:2),])
names(n.eco31)[1] <- 'n_train'
names(n.eco31)[2] <- 'n_test'

# Iwahashi Landform
n.ilf.train <- ddply(t.dc3, .(iwahashiLF_m), nrow)
n.ilf.val   <- ddply(v.dc4, .(iwahashiLF_m), nrow)
n.ilf1 <- cbind(n.ilf.train[,-1], n.ilf.val[,-1], ilf.acc[-c(1:2),])
names(n.ilf1)[1] <- 'n_train'
names(n.ilf1)[2] <- 'n_test'

# Plotting
require("ggrepel")

# Number of training observations
n.mlra1  %>%
 ggplot(aes(x=n_train, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("MLRA") + 
  labs(x = 'Number of training observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_ntraining_mlra.png", height=3, width=7)

n.eco31  %>%
 ggplot(aes(x=n_train, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("Ecoregion") + 
  labs(x = 'Number of training observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_ntraining_eco3.png", height=3, width=7)

n.ilf1  %>%
 ggplot(aes(x=n_train, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) + 
  ggtitle("Landform") + 
  labs(x = 'Number of training observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_ntraining_iwlf.png", height=3, width=7)


# Number of validation observations
n.mlra1  %>%
 ggplot(aes(x=n_test, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("MLRA") + 
  labs(x = 'Number of validation observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_nvalidation_mlra.png", height=3, width=7)

n.eco31  %>%
 ggplot(aes(x=n_test, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("Ecoregion") + 
  labs(x = 'Number of validation observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_nvalidation_eco3.png", height=3, width=7)

n.ilf1  %>%
 ggplot(aes(x=n_test, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("Landform") + 
  labs(x = 'Number of validation observations')
ggsave("Z:/UCRB/Figures/ValidationAccuray_vs_nvalidation_iwlf.png", height=3, width=7)

```


3.3. One explanation for the variable model performance may be the distribution of classes
Some areas had only a few observations in each depth class....
```{r}
# Calculate imbalance ration n observations of smallest class divided by n observations of largest class. 
# An imbalance ratio of 0.1 indicates that the smalles class has 10% of the number of observations of the largest class (e.g., 50/500). Smaller numbers mean that the data is more imbalanced. 

# define imbalance ratio function
ir <- function(x) min(x$Freq) / max(x$Freq)

# Calculate number of observations by class in training data
mlra.obs.by.class <- dlply(t.dc3, .(mlra_UCRB_m), function(x) as.data.frame(table(x$DepthClass)))
eco3.obs.by.class <- dlply(t.dc3, .(us_eco_l3_m), function(x) as.data.frame(table(x$DepthClass)))
iwlf.obs.by.class <- dlply(t.dc3, .(iwahashiLF_m), function(x) as.data.frame(table(x$DepthClass)))

# Apply function to get imbalance ratio
mlra.ir <- ldply(mlra.obs.by.class, ir)
mlra.ir <- cbind(mlra.acc[-c(1:2),],mlra.ir)
names(mlra.ir)[10] <- 'Imbalance.ratio'

eco3.ir <- ldply(eco3.obs.by.class, ir)
eco3.ir <- cbind(eco3.acc[-c(1:2),],eco3.ir)
names(eco3.ir)[10] <- 'Imbalance.ratio'

iwlf.ir <- ldply(iwlf.obs.by.class, ir)
iwlf.ir <- cbind(ilf.acc[-c(1:2),], iwlf.ir)
names(iwlf.ir)[10] <- 'Imbalance.ratio'

# Plotting
mlra.ir  %>%
 ggplot(aes(x=Imbalance.ratio, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("MLRA") + 
  labs(x = 'Imbalance Ratio')
ggsave("Z:/UCRB/Figures/ImbalanceRatio_mlra.png", height=3, width=7)

eco3.ir  %>%
 ggplot(aes(x=Imbalance.ratio, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("Ecoregion") + 
  labs(x = 'Imbalance Ratio')
ggsave("Z:/UCRB/Figures/ImbalanceRatio_eco3.png", height=3, width=7)

iwlf.ir  %>%
 ggplot(aes(x=Imbalance.ratio, y=Accuracy, label=.id)) +
  geom_point(size = 2.5) +
  geom_text_repel(size = 3) +
  ggtitle("Landform") + 
  labs(x = 'Imbalance Ratio')
ggsave("Z:/UCRB/Figures/ImbalanceRatio_iwlf.png", height=3, width=7)

```



4. Variable importance 
```{r}
# Variable importance as a dataframe
M1.varimp <- varImp(M1)
M2.varimp <- varImp(M2)
mlra.varimp <- llply(c.mlra, function (x) as.data.frame(varImp(x)$importance))
eco3.varimp <- llply(c.eco3, function (x) as.data.frame(varImp(x)$importance))
iwlf.varimp <- llply(c.iwlf, function (x) as.data.frame(varImp(x)$importance))


# Exceptionally Inelegant way to rename covariate names for better plotting
rownames(M1.varimp$importance) <- recode(rownames(M1.varimp$importance),
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature")


for (i in seq(mlra.varimp)) {
rownames(mlra.varimp[[i]]) <- recode(rownames(mlra.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature")
}

for (i in seq(eco3.varimp)) {
rownames(eco3.varimp[[i]]) <- recode(rownames(eco3.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature")
}

for (i in seq(iwlf.varimp)) {
rownames(iwlf.varimp[[i]]) <- recode(rownames(iwlf.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature")
}

# Give better names for plotting. This works because I preserved the order of list elements. 
names(mlra.varimp) <- c( 
"Great Salt Lake Area",  
"Mojave Desert",
'Cool Central Desertic Basins and Plateaus',
'Warm Central Desertic Basins and Plateaus',
'Colorado Plateau',
'Southwestern Plateaus, Mesas, and Foothills',
'Central Rocky Mountains',
'Wasatch and Uinta Mountains',
'Southern Rocky Mountains')

names(eco3.varimp) <- c(
'Central Basin and Range',
'Mojave Basin and Range',
'Middle Rockies',
'Wyoming Basin',
'Wasatch and Uinta Mountains',
'Colorado Plateaus',
'Southern Rockies',
'Arizona and New Mexico Plateau')

names(iwlf.varimp) <- c(
'Bedrock mountain',
'Hills',
'Large highland slope',
'Plateau, terrace, large lowland slope, plains')



# Plot variable importance for each model
# M1
M1.varimp$importance %>%
as.data.frame() %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
 ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
  ggtitle('Global Model') +
  coord_flip()
ggsave("Z:/UCRB/Figures/varimp_Global.png", height=3, width=7)

# M2 - pretty much the same as M1

#MLRA
for (i in 1:length(mlra.varimp)){
mlra.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(mlra.varimp)[i]) +
    coord_flip()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','mlra_', names(mlra.varimp)[i], ".png"), height=3, width=7)
}


#Ecoregion
for (i in 1:length(eco3.varimp)){
eco3.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(eco3.varimp)[i]) +
    coord_flip()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','eco3_', names(eco3.varimp)[i], ".png"), height=3, width=7)
}


#Landform
for (i in 1:length(iwlf.varimp)){
iwlf.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(iwlf.varimp)[i]) +
    coord_flip()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','iwlf_', names(iwlf.varimp)[i], ".png"), height=3, width=7)
}
```









5. Predictions
5.1 Set up covariates to make predictions. 
```{r}
library(raster)
# List all .tif files (all possible covariates) 
fil.tif <- list.files(path = "Z:/UCRB/Covariates", pattern = ".tif$", recursive = TRUE, full.names=TRUE)

# Subset list of all covariates for only those that were selected by the model (the predictors() function gets the variable names from each model)
covs <- grep(paste(predictors(M2), collapse="|"), fil.tif, value=TRUE)
# Manualy add to covariates. Don't really know why these aren't loading
covs1 <- c(covs, "Z:/UCRB/Covariates/PelletierCovariates/upland_valley-bottom_and_lowland_sedimentary_deposit_thickness_m.tif") 
covs2 <- c(covs1, "Z:/UCRB/Covariates/USGSCovariates/gammaUranium_m.tif")

# Create a raster stack for predictions
Mpred <- stack(covs2)

# For reasons entirely unclear the above raster stack duplicates a number of covariates and names the original and duplicates with .1 & .2 extensions. Fix this. also rename the SDT layer to match what is in model.
Mpred1 <- dropLayer(Mpred, grep("m.2", names(Mpred)))
names(Mpred1) <- gsub(".1$", "", names(Mpred1))
names(Mpred1) <- gsub("upland_valley.bottom_and_lowland_sedimentary_deposit_thickness_m$", "SDT", names(Mpred1))

#writeRaster(Mpred1, "Z:/UCRB/Covariates/Mpred1.tif")
```



5.2 Make predictions for global model (have to set up covariate stack to match training data)

5.3 Make predictions for global model without land class covariates
```{r}
rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()

raster::predict(object=Mpred1, model=M2, progress="text", filename = 'Z:/UCRB/Predictions/phy_area/M2.tif', datatype = 'INT1U', options=c("COMPRESS=LZW"))

raster::predict(object=Mpred1, model=M2, index = 1:6, type = 'prob', progress="text", filename = 'Z:/UCRB/Predictions/M2_prob.tif', datatype = 'FLT4S', options=c("COMPRESS=LZW"))

endCluster()
Sys.time()
```


5.4 Make predictions by area 
5.4.1 MLRA
```{r}
rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()
# some mlra's finished before running out of ram 1:length(c.mlra))

 for (i in 5:9)  {
 raster::predict(object=Mpred1, model=c.mlra[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra', names(c.mlra)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
 }

 for (i in 5:9) {
 raster::predict(object=Mpred1, model=c.mlra[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra',names(c.mlra)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
 }


endCluster()
Sys.time()
gc()
```


5.4.2 Ecoregion
```{r}
rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()

for (i in 1:length(c.eco3)) {
 raster::predict(object=Mpred1, model=c.eco3[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'eco3', names(c.eco3)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
 }

 for (i in 1:length(c.eco3)) {
 raster::predict(object=Mpred1, model=c.eco3[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'eco', names(c.iwlf)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
 }

endCluster()
Sys.time()
gc()
```




probably a problem with _m

5.4.3 Iwahashi Landform
```{r}
rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()

for (i in 1:length(c.iwlf)) {
 raster::predict(object=Mpred1, model=c.iwlf[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'iwlf', names(c.iwlf)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
}

 for (i in 1:length(c.iwlf)) {
 raster::predict(object=Mpred1, model=c.iwlf[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'iwlf', names(c.iwlf)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
 }

endCluster()
Sys.time()
gc()
```








To do: 
1. point buffer (synthetic observations)
2. calculate Tau for each model using validation observations. Where will priors come from? Maybe sampling proportions? Sampling proportions may be biased, but since I have a lot of them and this should tell me if I constrain the priors. 






MISC
```{r}
library(raster)
traster <- raster("Z:/testextent.tif")
testrast <- crop(Mpred1, traster, filename = "Z:/testraster.tif", overwrite=T)
names(testrast) <- names(Mpred1)
```












