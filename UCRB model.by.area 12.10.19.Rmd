---
title: "UCRB Modeling SoilDepth"
author: "cbrungard"
date: "August 24, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(error = TRUE)
library(tidyr)
library(caret)
library(sp)
library(doParallel)
library(forcats)
library(plyr)
library(measures)
library(raster)
```

1. Load observations and split into training and evaluation sets. 
```{r, include=FALSE}
# Read in regression matrix
obs <- read.csv("Z:/UCRB/Observations/regMatrix_7.1.19.csv")

#Force depth classes to be an ordered factor
obs$DepthClass <- factor(obs$DepthClass, levels = c('BR', 'VS', 'S', 'MD', 'D', 'VD'))

#Force Geographic stratifications to be factors
obs$GeoStrat4 <- factor(obs$GeoStrat4)      
obs$GeoStrat8 <- factor(obs$GeoStrat8)      
obs$GeoStrat9 <- factor(obs$GeoStrat9)

# I originally included lat/long as predictors. I am glad that I did this because they came out as important predictors which revealed that the clustering of data did have an impact, but including lat/long as covariates produces spurious spatial patterns in the predictions (they are often among the most important predictors). When I remove them accuracy drops ~ 3%, but remove them. Does this suggest that I should use regression kriging for continious attributes?

# Also remove GAP and NLCDcl factors because there are 93 levels of GAP (too many levels for RF) and NLCDcl classes 0 and 128 are never observed in the data. Also remove US_L4Name (EPA ecoregion IV), because it has too many levels

# After some thought, I also decided to exclude the standard deviation of the Landsat band ratios: 5/7, 5/4, and 5/1. While these were somewhat (not very) important predictors I can't explain them. The median values are intended to capture spatial variations in minerology/geology, but are obviously influenced by vegetation. Since I am including variability in NDVI (4/3) I feel that this captures vegetation variability and this I can explain. Interestlingly, when I remove these std deviations variables the model accuray and kappa both increase by 2-3%.

# The predictions had holes because of holes in the radar or imagery in areas of deep cliff or canyon. I've got enough observations that it is easiest to just drop these for now. My other option would be to fill the 'holes' in the the raster using inverse distance weighting (rfillspgaps in the meteo package), but I tried this and maxed out 32 GB memory (could probably do this with 64 GB Ram). I'm just going to remove these observations. After running the models without radar imagery I find that the accuracy drops ~ 0.5 to 1% (for both CV and independent validation). I think that this is justified as dropping the radar imagery means that I don't have big holes in the predictions. 

# Several variables were duplicated between what Travis and I calculated including: profile curvature tangential curvature, catchment area, and slope. Remove these duplicated variables; use those that I created as I am more familiar with them. 

# Also remove SiteID and depth (in cm) from the data
obs2 <- subset(obs, select=-c(SiteID,Depth,GAP,NLCDcl_m,L51_std_m,L54_std_m,L57_std_m,vv_med_m,vv_std_m,TCURV_rs_m,SLOPE_rs_m,PCURV_rs_m,CAlog_10_rs_m))

# Remove missing depth class values
obs3 <- drop_na(obs2)

# Reorder the data frame to put all land class variables at the begining. This just makes indexing easier. 
obs3 <- obs3[c(1:9,46,10:45,47:73)]

# Combine regions that only have a few observations (doing this here avoids trouble with accidently adding predictor columns, but I didn't figure this out until I tried modeling by region).
# MLRA 
# How many observations by mlra?
obs3$mlra_UCRB_m <- as.factor(obs3$mlra_UCRB_m)
table(obs3$mlra_UCRB_m)
# mlra id's 35:38, 51, 66 have < 200 points (all others have > ~ 400 points) and probably need to be merged
# mlra 35: Great Salt Lake Area, 36:Central Nevada Basin and Range, 37:Southern Nevada Basin and Range - combine into one class
# mlra 38: Mojave desert - seperate enough to leave as is, although it only has 204 points
# mlra 51: Arizona and NM mountains has only 122 points, join with colorado plateau
# mlra 66: Southern Rocky mountain parks has only 23 points - join with mlra:Southern Rock Mountains 
obs3$mlra_UCRB_m <- fct_collapse(obs3$mlra_UCRB_m, 
                            '35' = c('35','36','37'), 
                            '45' = c('45', '51'),
                            '65' = c('65','66'))
table(obs3$mlra_UCRB_m)

#Ecoregions
# How many observations by ecoregion?
obs3$us_eco_l3_m <- as.factor(obs3$us_eco_l3_m)
table(obs3$us_eco_l3_m)
# It appears that there are approximately equal numbers of observations by ecoregion (similar enough at least to mlra), that I do not need to combine ecoregions. This is probably because there are fewer, larger ecoregions. However; region 23 (Arizona/Nwe Mexico mountains) has no observations of bedrock so I need to combine this with region 22 (Arizona/New Mexico Plateau) to actually be able to run the model. 
obs3$us_eco_l3_m <- fct_collapse(obs3$us_eco_l3_m, 
                            '22' = c('22','23'))

# Iwahashi Landforms
obs3$iwahashiLF_m <- as.factor(obs3$iwahashiLF_m)
table(obs3$iwahashiLF_m)
# Categories 4, 13, 14, & 15 need to be combined as they have < 200 observations. After further review I decided to group Iwahashi landforms into broader categories by 'overview' groups that have equal overview groupings. Overview groupings are found in the file: legend_iwahasi_et_al_2018.xlsx that are provided with the dataset. These are 1: Bedrock mountain, 2:hills, 3:Large highland slope, 4:Plateau, terrace, large lowland slope, 5:Plain. Even after this grouping I had no bedrock observations in class 5:plain (only about 50 obs, rare class in this area), so I grouped these with class 4, which while not ideal, was the most similar category. 
obs3$iwahashiLF_m <- fct_collapse(obs3$iwahashiLF_m, 
                            "1" = c('1','2','3','4'),    
                            "2" = c('5','6'),    
                            "3" = c('7','8'),    
                            "4" = c('9','10','11','12','13','14','15'))
table(obs3$iwahashiLF_m)



# Split into training and test using the KSSL data and a random subset of 5% each class as validation. 
# Depth class
# Training
t.dc <- obs3[obs3$source != 'KSSL',]
dc.index <- createDataPartition(t.dc$DepthClass, p = 0.95, list = FALSE)
t.dc2 <- t.dc[dc.index, ]
#write.csv(t.dc2, "Z:/UCRB/Observations/t.dc2.csv")
# Remove source, x, and y fields. This makes coding a bit easier, but leaves t.dc2 available for plotting 
t.dc3 <- t.dc2[,-c(2:4)]

#Validation (I may need to think about bedrock since KSSL data has no bedrock observations this effectively 'undersamples' bedrock in the validation data...)
v.dc <- obs3[obs3$source == 'KSSL',]
v.dc2 <- t.dc[-dc.index, ]
v.dc3 <- rbind(v.dc, v.dc2)
#write.csv(v.dc3, "Z:/UCRB/Observations/v.dc3.csv")
# Remove source, x, and y fields. This makes coding a bit easier, but leaves v.dc3 available for plotting 
v.dc4 <- v.dc3[,-c(2:4)]
```

2. Modeling
Set up model tuning parameters that will be used repeatedly. 
Note: I initially used ranger to speed up the model fitting, but abandoned this because I was unable to get class probability predictions from ranger models. I believe this to be because including the argument probability=TRUE makes it impossible for caret to calculate accuracy. Also, ranger didnt seem much faster than the base random forests.

```{r}
# Set up resampling options: 10 fold cross validation
fitControl <- trainControl(method = "cv", 
                           savePredictions = T, 
                           returnResamp = 'final',
                           allowParallel = TRUE,
                           selectionFunction='oneSE',
                           summaryFunction = multiClassSummary)


# Set a tune grid for manual control of tuning parameters
tunegrid <- expand.grid(mtry=c(2:10,15))
```

A function for implementing model tuning by region. The x[,-2] argument is necessary to remove the categorical land classification variable when fitting the model by region. 
```{r}
region.train <- function(x) {
  train(DepthClass ~ ., data = x[,-2], method="rf", trControl = fitControl, tuneGrid=tunegrid)
}
```


2.1 Build global depth class model with all variables. 
It is important to use the formula interface with these models, otherwise the predict function throws an error about not matching data types. Super annoying! 
```{r, message=FALSE, warning=FALSE, include=FALSE}
# Register parallel processing
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# M1 = train(DepthClass ~ ., data = t.dc3[-c(2:4)], method="rf", trControl = fitControl, tuneGrid=tunegrid)
# stopCluster(cl)
# M1
```

2.2 Build global depth class model not including the categorical land classifications.
```{r, include=FALSE}
# # Set up parallization
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# M2 = train(DepthClass ~ ., data = t.dc3[,-c(2:7)], method="rf", trControl = fitControl, tuneGrid=tunegrid)
# stopCluster(cl)
# M2
```


2.3 Build models by physiographic area
Split the training/testing data by area. 
```{r}
t.mlra <- split(t.dc3[,-c(2,3,4,6,7)], f = t.dc3$mlra_UCRB_m)
t.eco3 <- split(t.dc3[,-c(2,3,4,5,7)], f = t.dc3$us_eco_l3_m)
t.iwlf <- split(t.dc3[,-c(2,3,4,5,6)], f = t.dc3$iwahashiLF_m)

t.g4 <- split(t.dc3[,-c(3:7)], f = t.dc3$GeoStrat4)
t.g8 <- split(t.dc3[,-c(2,4:7)], f = t.dc3$GeoStrat8)
t.g9 <- split(t.dc3[,-c(2:3,5:7)], f = t.dc3$GeoStrat9)

# There is no need to subset to remove predictors for the validattion data, hence I don't subset
v.mlra <- split(v.dc4, f = v.dc4$mlra_UCRB_m)
v.eco3 <- split(v.dc4, f = v.dc4$us_eco_l3_m)
v.iwlf <- split(v.dc4, f = v.dc4$iwahashiLF_m)

v.g4 <-   split(v.dc4, f = v.dc4$GeoStrat4)
v.g8 <-   split(v.dc4, f = v.dc4$GeoStrat8)
v.g9 <-   split(v.dc4, f = v.dc4$GeoStrat9)
```

Make predictions
(the following has been commented to avoid re-running the models, which would require rerunning the predictions)
```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.mlra <- llply(t.mlra, region.train)
# stopCluster(cl)
# c.mlra
# ```
# 
# 2.3.2 By Ecoregion
# ```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.eco3 <- llply(t.eco3, region.train)
# stopCluster(cl)
# c.eco3
# ```
# 
# 2.3.2 By broad landform (iwahashi)
# ```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.iwlf <- llply(t.iwlf, region.train)
# stopCluster(cl)
# c.iwlf
# ```
# 
# 
# 2.4 By Geographic Area (not physiographic area)
# 2.4.1 Nine geographic areas (matches the number of MLRAs)
# Strata 0 and 6 do not have BR obs so I manually added observations in these areas.  
# ```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.g9 <- llply(t.g9, region.train)
# stopCluster(cl)
# c.g9
# ```
# 
# 2.4.2 Eight geographic areas (matches number of ecoregions)
# Strata 4 does not have BR obs so I manually added observations in this area
# ```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.g8 <- llply(t.g8, region.train)
# stopCluster(cl)
# c.g8
# ```
# 
# 2.4.3 Four geographic areas (matches number of landforms)
# ```{r, include=FALSE}
# cl <- makePSOCKcluster(30)
# registerDoParallel(cl)
# set.seed(4801)
# c.g4 <- llply(t.g4, region.train)
# stopCluster(cl)
# c.g4
```


3. Compare model performance using an independent validation subset
3.1 Calculate model accuracy
```{r}
# Global models
# With land classifications
M1.pred <- predict(M1, newdata = v.dc4)
M1.cm <- confusionMatrix(data=M1.pred, reference = v.dc4$DepthClass)

# Without land classifications
M2.pred <- predict(M2, newdata = v.dc4)
M2.cm <- confusionMatrix(data=M2.pred, reference = v.dc4$DepthClass)

# Physiographic regions
# By mlra
# Use all regional models to predict all validation data (I later subset only the relevant regional data)
mlra.pred <- llply(c.mlra, predict, newdata=v.dc4)
# Calculate a confusion matrix for only the validation data that is within each region
mlra.cm <- list()
for(i in names(mlra.pred)) {
mlra.cm[[i]] <- (confusionMatrix(data=mlra.pred[[i]][v.dc4$mlra_UCRB_m == i], reference=v.dc4[v.dc4$mlra_UCRB_m == i,1]))
}

# Ecoregion
eco3.pred <- llply(c.eco3, predict, newdata=v.dc4)
eco3.cm <- list()
for(i in names(eco3.pred)) {
eco3.cm[[i]] <- (confusionMatrix(data=eco3.pred[[i]][v.dc4$us_eco_l3_m == i], reference=v.dc4[v.dc4$us_eco_l3_m == i,1]))
}

#Landform
ilf.pred <- llply(c.iwlf, predict, newdata=v.dc4)
ilf.cm <- list()
for(i in names(ilf.pred)) {
ilf.cm[[i]] <- (confusionMatrix(data=ilf.pred[[i]][v.dc4$iwahashiLF_m == i], reference=v.dc4[v.dc4$iwahashiLF_m == i,1]))
}


# Geographic regions
# 9 regions
g9.pred <- llply(c.g9, predict, newdata=v.dc4)
g9.cm <- list()
for(i in names(g9.pred)) {
g9.cm[[i]] <- (confusionMatrix(data=g9.pred[[i]][v.dc4$GeoStrat9 == i], reference=v.dc4[v.dc4$GeoStrat9 == i,1]))
}

# 8 regions
g8.pred <- llply(c.g8, predict, newdata=v.dc4)
g8.cm <- list()
for(i in names(g8.pred)) {
g8.cm[[i]] <- (confusionMatrix(data=g8.pred[[i]][v.dc4$GeoStrat8 == i], reference=v.dc4[v.dc4$GeoStrat8 == i,1]))
}

# 4 regions
g4.pred <- llply(c.g4, predict, newdata=v.dc4)
g4.cm <- list()
for(i in names(g4.pred)) {
g4.cm[[i]] <- (confusionMatrix(data=g4.pred[[i]][v.dc4$GeoStrat4 == i], reference=v.dc4[v.dc4$GeoStrat4 == i,1]))
}


# Use the global model (without land classification covariates) to predict the validation data in each MLRA, etc. Wish I could get this to work with dplyr, etc.
# Physiographic regions
# MLRA
# m2 is used in the names because I'm using model m2 
mlra.m2.pred <- list()
for (i in names(v.mlra)) {
  mlra.m2.pred[[i]] <- predict(M2, newdata = v.mlra[[i]])
}
  
mlra.m2.cm <- list()
for(i in names(mlra.m2.pred)) {
mlra.m2.cm[[i]] <- (confusionMatrix(data=mlra.m2.pred[[i]], reference=v.mlra[[i]]$DepthClass))
}

# Ecoregion
eco3.m2.pred <- list()
for (i in names(v.eco3)) {
  eco3.m2.pred[[i]] <- predict(M2, newdata = v.eco3[[i]])
}
  
eco3.m2.cm <- list()
for(i in names(eco3.m2.pred)) {
eco3.m2.cm[[i]] <- (confusionMatrix(data=eco3.m2.pred[[i]], reference=v.eco3[[i]]$DepthClass))
}

# Landform
iwlf.m2.pred <- list()
for (i in names(v.iwlf)) {
  iwlf.m2.pred[[i]] <- predict(M2, newdata = v.iwlf[[i]])
}
  
iwlf.m2.cm <- list()
for(i in names(iwlf.m2.pred)) {
iwlf.m2.cm[[i]] <- (confusionMatrix(data=iwlf.m2.pred[[i]], reference=v.iwlf[[i]]$DepthClass))
}


# Geographic Regions
# 9 regions
g9.m2.pred <- list()
for (i in names(v.g9)) {
  g9.m2.pred[[i]] <- predict(M2, newdata = v.g9[[i]])
}
  
g9.m2.cm <- list()
for(i in names(g9.m2.pred)) {
g9.m2.cm[[i]] <- (confusionMatrix(data=g9.m2.pred[[i]], reference=v.g9[[i]]$DepthClass))
}

# 8 regions
g8.m2.pred <- list()
for (i in names(v.g8)) {
  g8.m2.pred[[i]] <- predict(M2, newdata = v.g8[[i]])
}
  
g8.m2.cm <- list()
for(i in names(g8.m2.pred)) {
g8.m2.cm[[i]] <- (confusionMatrix(data=g8.m2.pred[[i]], reference=v.g8[[i]]$DepthClass))
}

# 4 regions
g4.m2.pred <- list()
for (i in names(v.g4)) {
  g4.m2.pred[[i]] <- predict(M2, newdata = v.g4[[i]])
}
  
g4.m2.cm <- list()
for(i in names(g4.m2.pred)) {
g4.m2.cm[[i]] <- (confusionMatrix(data=g4.m2.pred[[i]], reference=v.g4[[i]]$DepthClass))
}
```

Plot validation accuracies
```{r}
# Get accuracy metrics for each regional model as a dataframe 
mlra.cm.df <- ldply(mlra.cm, "[[", 3)
eco3.cm.df <- ldply(eco3.cm, "[[", 3)
ilf.cm.df  <- ldply(ilf.cm, "[[", 3)

g9.cm.df <- ldply(g9.cm, "[[", 3)
g8.cm.df <- ldply(g8.cm, "[[", 3)
g4.cm.df <- ldply(g4.cm, "[[", 3)

# Create a variable in each dataframe defining these as regional model results
mlra.cm.df$ModelType <- 'Regional'
eco3.cm.df$ModelType <- 'Regional'
ilf.cm.df$ModelType <- 'Regional'
g9.cm.df$ModelType <- 'Regional'
g8.cm.df$ModelType <- 'Regional'
g4.cm.df$ModelType <- 'Regional'

# Get accuracy metrics of the global model applied to each region as a dataframe 
mlra.cm.m2.df <- ldply(mlra.m2.cm, "[[", 3)
eco3.cm.m2.df <- ldply(eco3.m2.cm, "[[", 3)
iwlf.cm.m2.df <- ldply(iwlf.m2.cm, "[[", 3)

g9.cm.m2.df   <- ldply(g9.m2.cm, "[[", 3)
g8.cm.m2.df   <- ldply(g8.m2.cm, "[[", 3)
g4.cm.m2.df   <- ldply(g4.m2.cm, "[[", 3)

# Create a variable in each dataframe defining these as global model results
mlra.cm.m2.df$ModelType <- 'Global'
eco3.cm.m2.df$ModelType <- 'Global'
iwlf.cm.m2.df$ModelType <- 'Global'
g9.cm.m2.df$ModelType <- 'Global'
g8.cm.m2.df$ModelType <- 'Global'
g4.cm.m2.df$ModelType <- 'Global'


# Join regional and global model accuracy dataframes
mlra.acc <- rbind(mlra.cm.df, mlra.cm.m2.df) 
eco3.acc <- rbind(eco3.cm.df, eco3.cm.m2.df)
ilf.acc  <- rbind(ilf.cm.df,  iwlf.cm.m2.df)

g9.acc <- rbind(g9.cm.df, g9.cm.m2.df)
g8.acc <- rbind(g8.cm.df, g8.cm.m2.df)
g4.acc <- rbind(g4.cm.df, g4.cm.m2.df)


# Rename land classes with meaningful names for plotting
library(dplyr)
mlra.acc$.id <- as.character(mlra.acc$.id)
eco3.acc$.id <- as.character(eco3.acc$.id)
ilf.acc$.id <- as.character(ilf.acc$.id)

g9.acc$.id <- as.character(g9.acc$.id)
g8.acc$.id <- as.character(g8.acc$.id)
g4.acc$.id <- as.character(g4.acc$.id)

mlra.acc$.id <- recode(mlra.acc$.id, 
                      `35` = "Great Salt Lake Area",  
                      `38` = "Mojave Desert",
                      `43` = 'Cool Central Desertic Basins and Plateaus',
                      `44` = 'Warm Central Desertic Basins and Plateaus',
                      `45` = 'Colorado Plateau',
                      `46` = 'Southwestern Plateaus, Mesas, and Foothills',
                      `60` = 'Central Rocky Mountains',
                      `64` = 'Wasatch and Uinta Mountains',
                      `65` = 'Southern Rocky Mountains')

eco3.acc$.id <- recode(eco3.acc$.id,
                      `13` =	'Central Basin and Range',
                      `14` =	'Mojave Basin and Range',
                      `17` =	'Middle Rockies',
                      `18` =	'Wyoming Basin',
                      `19` =	'Wasatch and Uinta Mountains',
                      `20` =	'Colorado Plateaus',
                      `21` =	'Southern Rockies',
                      `22` =	'Arizona and New Mexico Plateau')

ilf.acc$.id <- recode(ilf.acc$.id,
                      `1` =	'Bedrock mountain',
                      `2` =	'Hills',
                      `3` =	'Large highland slope',
                      `4` =	'Plateau, terrace, slope, plains')

g9.acc$.id <- recode(g9.acc$.id,
                     `0` = '1', 
                     `1` = '2',
                     `2` = '3',
                     `3` = '4',
                     `4` = '5',
                     `5` = '6',
                     `6` = '7',
                     `7` = '8',
                     `8` = '9')
                     
g8.acc$.id <- recode(g8.acc$.id,
                     `0` = '1', 
                     `1` = '2',
                     `2` = '3',
                     `3` = '4',
                     `4` = '5',
                     `5` = '6',
                     `6` = '7',
                     `7` = '8')

g4.acc$.id <- recode(g4.acc$.id,
                     `0` = '1', 
                     `1` = '2',
                     `2` = '3',
                     `3` = '4')
                     

# Plot. Note: ''confusionMatrix' calculates accuracyUpper and accuracyLower using a binomial distribution. I dont think this makes sense in a multi-class scenario.
library(ggplot2)
library(ggpubr)
library(stringr)

# Validation accuracy
# Physiographic regions
# MLRA
pmlra <- 
mlra.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') + 
  xlab("Accuracy") +
  ggtitle('MLRA') + 
  ylim(0.5, 0.9) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())
#ggsave("Z:/UCRB/Figures/ValidationAccuracy_MLRA.png", height=2, width=5) #

# Ecoregion
peco3 <- 
eco3.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') +
  xlab("Accuracy") +
  ggtitle('Ecoregion') + 
  ylim(0.5, 0.9) +
  coord_flip() + 
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) +
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())
#ggsave("Z:/UCRB/Figures/ValidationAccuracy_eco3.png", height=3, width=5)

# Landform
pilf <- 
ilf.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') +
  xlab("Accuracy") +
  ggtitle('Landforms') + 
  ylim(0.5, 0.9) +
  coord_flip() + 
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) +
  theme_bw() + 
  theme(axis.title.y=element_blank(), legend.title=element_blank())
#ggsave("Z:/UCRB/Figures/ValidationAccuracy_iwlf.png", height=1.5, width=5)


# Geographic regions
# 9 areas
p9 <- 
g9.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') +
  xlab("Accuracy") +
  ggtitle('9 geographic areas') + 
  ylim(0.5, 0.9) +
  coord_flip() + 
  theme_bw()+ 
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())
#ggsave("Z:/UCRB/Figures/ValidationAccuracy_geo9.png", height=3, width=3)

# 8 areas
p8 <- 
g8.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy, shape=ModelType)) +
  geom_point(aes(color=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') +
  xlab("Accuracy") +
  ggtitle('8 geographic areas') +
  ylim(0.5, 0.9) +
  coord_flip() +
  theme_bw() + 
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())
#ggsave("Z:/UCRB/Figures/ValidationAccuracy_geo8.png", height=3, width=3)

# 4 areas
p4 <- 
g4.acc %>%
  mutate(.id = fct_reorder(.id, Accuracy)) %>%
  ggplot(aes(x=.id, y=Accuracy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.cm$overall[1], linetype = 'dashed') +
  xlab("Accuracy") +
  ggtitle('4 geographic areas') +
  ylim(0.5, 0.9) +
  coord_flip() + 
  theme_bw() + 
  theme(axis.title.y=element_blank(), legend.title=element_blank())


# Plotting
library(gridExtra)
library(ggpubr)
# Put all physiographic plots into one figure
ggarrange(pmlra, peco3, pilf, ncol = 3, common.legend = TRUE, legend = 'right')
ggsave("Z:/UCRB/Figures/ValidationAccuracy_physAll.png", height = 3.75, width = 10)

# Put all geographic plots into one figure
ggarrange(p9, p8, p4, ncol = 3, common.legend = TRUE, legend = 'right', font.label = list(size = 0.5))
ggsave("Z:/UCRB/Figures/ValidationAccuracy_geoAll.png", height = 3.75)
```

What if I used one regional model (e.g., colorado plateau to predict the other areas?). 
This shows that accuracy drops ALOT when one model is applied to the other areas.   
```{r}

# Use one regional model (mlra 35 = colordao plateau) to predict all validation data 
test.pred <- predict(c.mlra[[1]], newdata=v.dc4)

test.pred <- list()
for(i in names(mlra.pred)) {
test.pred[[i]] <- predict(c.mlra[[1]], newdata=v.dc4[v.dc4$mlra_UCRB_m == i,])
}

# Calculate a confusion matrix for only the validation data that is within each region
test.cm <- list()
for(i in names(test.pred)) {
test.cm[[i]] <- (confusionMatrix(test.pred[[i]], reference=v.dc4[v.dc4$mlra_UCRB_m == i,1]))
}
```


3.2 Brier scores 
Which model most often predicted the correct class with the highest probability. We would have more confidence in the model that predicts the correct class with a higher probability than one that predicts the correct class with a lower probability. In this case, a lower brier score is better. In this sense the brier score is a 'skill' score. A model with better brier score is more skilled at making the correct predictions.

First predict the probabilities of the validation datasets. This must be done before calculation of brier scores or shannon's entropy.  
```{r, Predict probabilities}
# I really should put most of this in a function: https://stackoverflow.com/questions/8497160/using-predict-with-a-list-of-lm-objects 

# Global model without land classification covariates
M2.pred.p <- predict(M2, newdata = v.dc4, type = 'prob')

# Regional models
# Physiographic regions
# By mlra
mlra.pred.p <- list()
for(i in names(c.mlra)) {
mlra.pred.p[[i]] <- predict(c.mlra[[i]], newdata = v.mlra[[i]], type = 'prob')
}

# Ecoregion
eco3.pred.p <- list()
for(i in names(c.eco3)) {
eco3.pred.p[[i]] <- predict(c.eco3[[i]], newdata = v.eco3[[i]], type = 'prob')
}

# Landform
iwlf.pred.p <- list()
for(i in names(c.iwlf)) {
iwlf.pred.p[[i]] <- predict(c.iwlf[[i]], newdata = v.iwlf[[i]], type = 'prob')
}

# Geographic regions
# 9 regions
g9.pred.p <- list()
for(i in names(c.g9)) {
g9.pred.p[[i]] <- predict(c.g9[[i]], newdata = v.g9[[i]], type = 'prob')
}

# 8 regions
g8.pred.p <- list()
for(i in names(c.g8)) {
g8.pred.p[[i]] <- predict(c.g8[[i]], newdata = v.g8[[i]], type = 'prob')
}

# 4 regions
g4.pred.p <- list()
for(i in names(c.g4)) {
g4.pred.p[[i]] <- predict(c.g4[[i]], newdata = v.g4[[i]], type = 'prob')
}


# Use the global model (without land classification covariates) to predict the validation data in each MLRA, etc. 
# Physiographic regions
# MLRA
mlra.m2.pred.p <- list()
for (i in names(v.mlra)) {
  mlra.m2.pred.p[[i]] <- predict(M2, newdata = v.mlra[[i]], type = 'prob')
}
  
# Ecoregion
eco3.m2.pred.p <- list()
for (i in names(v.eco3)) {
  eco3.m2.pred.p[[i]] <- predict(M2, newdata = v.eco3[[i]], type = 'prob')
}
  
# Landform
iwlf.m2.pred.p <- list()
for (i in names(v.iwlf)) {
  iwlf.m2.pred.p[[i]] <- predict(M2, newdata = v.iwlf[[i]], type = 'prob')
}
  
# Geographic Regions
# 9 regions
g9.m2.pred.p <- list()
for (i in names(v.g9)) {
  g9.m2.pred.p[[i]] <- predict(M2, newdata = v.g9[[i]], type = 'prob')
}
  
# 8 regions
g8.m2.pred.p <- list()
for (i in names(v.g8)) {
  g8.m2.pred.p[[i]] <- predict(M2, newdata = v.g8[[i]], type = 'prob')
}
  
# 4 regions
g4.m2.pred.p <- list()
for (i in names(v.g4)) {
  g4.m2.pred.p[[i]] <- predict(M2, newdata = v.g4[[i]], type = 'prob')
}
```
 
Calculate Brier Scores 
(I really should write a function to do this, but this is difficult since I have to call data from two different data frames. I probably just need to bind the v.mlra[[]]$DepthClass to the predicted dataframe in the list. Then call from this.)
```{r}
library(measures)

# Global model
M2.bs <- multiclass.Brier(M2.pred.p, v.dc4$DepthClass)

# Regional Models
# Physiographic regions
# MLRA
mlra.bs <- list()
for(i in names(mlra.pred.p)) {
mlra.bs[[i]] <- multiclass.Brier(mlra.pred.p[[i]], v.mlra[[i]]$DepthClass)
}

# Ecoregion
eco3.bs <- list()
for(i in names(eco3.pred.p)) {
eco3.bs[[i]] <- multiclass.Brier(eco3.pred.p[[i]], v.eco3[[i]]$DepthClass)
}

# Landform
iwlf.bs <- list()
for(i in names(iwlf.pred.p)) {
iwlf.bs[[i]] <- multiclass.Brier(iwlf.pred.p[[i]], v.iwlf[[i]]$DepthClass)
}

# Geographic regions
# 9 regions
g9.bs <- list()
for(i in names(g9.pred.p)) {
g9.bs[[i]] <- multiclass.Brier(g9.pred.p[[i]], v.g9[[i]]$DepthClass)
}

# 8 regions
g8.bs <- list()
for(i in names(g8.pred.p)) {
g8.bs[[i]] <- multiclass.Brier(g8.pred.p[[i]], v.g8[[i]]$DepthClass)
}

# 4 regions
g4.bs <- list()
for(i in names(g4.pred.p)) {
g4.bs[[i]] <- multiclass.Brier(g4.pred.p[[i]], v.g4[[i]]$DepthClass)
}


# Global model applied to each region
# Physiographic regions
# MLRA
mlra.bs.g <- list()
for(i in names(mlra.m2.pred.p)) {
mlra.bs.g[[i]] <- multiclass.Brier(mlra.m2.pred.p[[i]], v.mlra[[i]]$DepthClass)
}

# Ecoregion
eco3.bs.g <- list()
for(i in names(eco3.m2.pred.p)) {
eco3.bs.g[[i]] <- multiclass.Brier(eco3.m2.pred.p[[i]], v.eco3[[i]]$DepthClass)
}

# Landforms
iwlf.bs.g <- list()
for(i in names(iwlf.m2.pred.p)) {
iwlf.bs.g[[i]] <- multiclass.Brier(iwlf.m2.pred.p[[i]], v.iwlf[[i]]$DepthClass)
}

# Geographic regions
# 9
g9.bs.g <- list()
for(i in names(g9.m2.pred.p)) {
g9.bs.g[[i]] <- multiclass.Brier(g9.m2.pred.p[[i]], v.g9[[i]]$DepthClass)
}

# 8 
g8.bs.g <- list()
for(i in names(g8.m2.pred.p)) {
g8.bs.g[[i]] <- multiclass.Brier(g8.m2.pred.p[[i]], v.g8[[i]]$DepthClass)
}

# 4
g4.bs.g <- list()
for(i in names(g4.m2.pred.p)) {
g4.bs.g[[i]] <- multiclass.Brier(g4.m2.pred.p[[i]], v.g4[[i]]$DepthClass)
}
```

Formatting for Brier score plotting
```{r}
# Physiographic
# MLRA
# Regional 
mlra.bs.regional <- data.frame(cbind(unlist(mlra.bs), rep('Regional', length(mlra.bs))))
names(mlra.bs.regional) <- c('BrierScore', 'ModelType')
mlra.bs.regional$BrierScore <- as.numeric(as.character(mlra.bs.regional$BrierScore))
mlra.bs.regional$.id <- c( 
                      "Great Salt Lake Area",  
                      "Mojave Desert",
                      'Cool Central Desertic Basins and Plateaus',
                      'Warm Central Desertic Basins and Plateaus',
                      'Colorado Plateau',
                      'Southwestern Plateaus, Mesas, and Foothills',
                      'Central Rocky Mountains',
                      'Wasatch and Uinta Mountains',
                      'Southern Rocky Mountains')
                                     
# Global
mlra.bs.global <- data.frame(cbind(unlist(mlra.bs.g), rep('Global', length(mlra.bs.g))))
names(mlra.bs.global) <- c('BrierScore', 'ModelType')
mlra.bs.global$BrierScore <- as.numeric(as.character(mlra.bs.global$BrierScore))
mlra.bs.global$.id <- c( 
                      "Great Salt Lake Area",  
                      "Mojave Desert",
                      'Cool Central Desertic Basins and Plateaus',
                      'Warm Central Desertic Basins and Plateaus',
                      'Colorado Plateau',
                      'Southwestern Plateaus, Mesas, and Foothills',
                      'Central Rocky Mountains',
                      'Wasatch and Uinta Mountains',
                      'Southern Rocky Mountains')

# Join regional and global
mlra.bs.all <- rbind(mlra.bs.regional, mlra.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
mlra.bs.all$ModelType <- relevel(mlra.bs.all$ModelType, "Global")

# Ecosite
# Regional 
eco3.bs.regional <- data.frame(cbind(unlist(eco3.bs), rep('Regional', length(eco3.bs))))
names(eco3.bs.regional) <- c('BrierScore', 'ModelType')
eco3.bs.regional$BrierScore <- as.numeric(as.character(eco3.bs.regional$BrierScore))
eco3.bs.regional$.id <- c( 
                      'Central Basin and Range',
                      'Mojave Basin and Range',
                      'Middle Rockies',
                      'Wyoming Basin',
                      'Wasatch and Uinta Mountains',
                      'Colorado Plateaus',
                      'Southern Rockies',
                      'Arizona and New Mexico Plateau')
                                     
# Global
eco3.bs.global <- data.frame(cbind(unlist(eco3.bs.g), rep('Global', length(eco3.bs.g))))
names(eco3.bs.global) <- c('BrierScore', 'ModelType')
eco3.bs.global$BrierScore <- as.numeric(as.character(eco3.bs.global$BrierScore))
eco3.bs.global$.id <- c( 
                      'Central Basin and Range',
                      'Mojave Basin and Range',
                      'Middle Rockies',
                      'Wyoming Basin',
                      'Wasatch and Uinta Mountains',
                      'Colorado Plateaus',
                      'Southern Rockies',
                      'Arizona and New Mexico Plateau')

# Join regional and global
eco3.bs.all <- rbind(eco3.bs.regional, eco3.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
eco3.bs.all$ModelType <- relevel(eco3.bs.all$ModelType, "Global")

# Landform
# Regional 
iwlf.bs.regional <- data.frame(cbind(unlist(iwlf.bs), rep('Regional', length(iwlf.bs))))
names(iwlf.bs.regional) <- c('BrierScore', 'ModelType')
iwlf.bs.regional$BrierScore <- as.numeric(as.character(iwlf.bs.regional$BrierScore))
iwlf.bs.regional$.id <- c( 
                      'Bedrock mountain',
                      'Hills',
                      'Large highland slope',
                      'Plateau, terrace, slope, plains')
                                     
# Global
iwlf.bs.global <- data.frame(cbind(unlist(iwlf.bs.g), rep('Global', length(iwlf.bs.g))))
names(iwlf.bs.global) <- c('BrierScore', 'ModelType')
iwlf.bs.global$BrierScore <- as.numeric(as.character(iwlf.bs.global$BrierScore))
iwlf.bs.global$.id <- c( 
                      'Bedrock mountain',
                      'Hills',
                      'Large highland slope',
                      'Plateau, terrace, slope, plains')

# Join regional and global
iwlf.bs.all <- rbind(iwlf.bs.regional, iwlf.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
iwlf.bs.all$ModelType <- relevel(iwlf.bs.all$ModelType, "Global")


# Geographic
# 9
# Regional 
g9.bs.regional <- data.frame(cbind(unlist(g9.bs), rep('Regional', length(g9.bs))))
names(g9.bs.regional) <- c('BrierScore', 'ModelType')
g9.bs.regional$BrierScore <- as.numeric(as.character(g9.bs.regional$BrierScore))
g9.bs.regional$.id <- c('1', '2', '3', '4', '5', '6', '7', '8', '9')
                                     
# Global
g9.bs.global <- data.frame(cbind(unlist(g9.bs.g), rep('Global', length(g9.bs.g))))
names(g9.bs.global) <- c('BrierScore', 'ModelType')
g9.bs.global$BrierScore <- as.numeric(as.character(g9.bs.global$BrierScore))
g9.bs.global$.id <- c('1', '2', '3', '4', '5', '6', '7', '8', '9')

# Join regional and global
g9.bs.all <- rbind(g9.bs.regional, g9.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
g9.bs.all$ModelType <- relevel(g9.bs.all$ModelType, "Global")


# 8
# Regional 
g8.bs.regional <- data.frame(cbind(unlist(g8.bs), rep('Regional', length(g8.bs))))
names(g8.bs.regional) <- c('BrierScore', 'ModelType')
g8.bs.regional$BrierScore <- as.numeric(as.character(g8.bs.regional$BrierScore))
g8.bs.regional$.id <- c('1', '2', '3', '4', '5', '6', '7', '8')
                                     
# Global
g8.bs.global <- data.frame(cbind(unlist(g8.bs.g), rep('Global', length(g8.bs.g))))
names(g8.bs.global) <- c('BrierScore', 'ModelType')
g8.bs.global$BrierScore <- as.numeric(as.character(g8.bs.global$BrierScore))
g8.bs.global$.id <- c('1', '2', '3', '4', '5', '6', '7', '8')

# Join regional and global
g8.bs.all <- rbind(g8.bs.regional, g8.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
g8.bs.all$ModelType <- relevel(g8.bs.all$ModelType, "Global")


# 4
# Regional 
g4.bs.regional <- data.frame(cbind(unlist(g4.bs), rep('Regional', length(g4.bs))))
names(g4.bs.regional) <- c('BrierScore', 'ModelType')
g4.bs.regional$BrierScore <- as.numeric(as.character(g4.bs.regional$BrierScore))
g4.bs.regional$.id <- c('1', '2', '3', '4')
                                     
# Global
g4.bs.global <- data.frame(cbind(unlist(g4.bs.g), rep('Global', length(g4.bs.g))))
names(g4.bs.global) <- c('BrierScore', 'ModelType')
g4.bs.global$BrierScore <- as.numeric(as.character(g4.bs.global$BrierScore))
g4.bs.global$.id <- c('1', '2', '3', '4')

# Join regional and global
g4.bs.all <- rbind(g4.bs.regional, g4.bs.global)
# Reorder the factor levels of ModelType so that it matchs the accuracy plots
g4.bs.all$ModelType <- relevel(g4.bs.all$ModelType, "Global")
```

Brier score plotting
```{r}
# Physiographic areas
pmlra.bs <- 
mlra.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('MLRA') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

peco3.bs <-
eco3.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('Ecoregion') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 20)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

piwlf.bs <-
iwlf.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('Landform') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 20)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


# Geographic areas
pg9.bs <-
g9.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('9 Geographic Areas') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

pg8.bs <-
g8.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('8 Geographic Areas') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


pg4.bs <-
g4.bs.all %>%
  mutate(.id = fct_reorder(.id, BrierScore, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=BrierScore)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.bs, linetype = 'dashed') + 
  xlab("Brier Score") +
  ggtitle('4 Geographic Areas') + 
  ylim(0.3, 0.6) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 10)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


# I might need to save these individually.



# Plot all on one figure
library(gridExtra)
library(ggpubr)
# Put all physiographic plots into one figure
ggarrange(pmlra.bs, peco3.bs, piwlf.bs, ncol = 3, common.legend = TRUE, legend = 'right', widths = c(3,3,3))
ggsave("Z:/UCRB/Figures/BriarScore_physAll.png", height = 3.75, width = 10)

# Put all geographic plots into one figure
ggarrange(pg9.bs, pg8.bs, pg4.bs, ncol = 3, common.legend = TRUE, legend = 'right')
ggsave("Z:/UCRB/Figures/BriarScore_geoAll.png", height = 3.75)
```


3.3 Shannon's entropy. 
Which model was the least uncertain about the predictions it made, even if they were wrong. Larger values indicate greater uncertainty. This can also be thought of as purity. A value of zero indicates that one class was predicted with a probablity of  1 and the other classes were predicted with a probability of 0. 

Calculate Shannon's entropy - scaled using log-base = number of classes, which makes it easy to compare. Code and ideas from: https://github.com/ISRICWorldSoil/GSIF_tutorials/blob/master/eberg/uncertainty_ranger.R
```{r Shannon Entropy}
# Define a function to calculate shannon's entropy. Using base = length() scales this from 0 to 1.
ses <- function(p) {
  sum(-p*log(p,base=length(p)), na.rm=TRUE)
}

# Calculate the average scaled entropy
# Global model
M2.se <- mean(apply(M2.pred.p, 1, ses))

# Regional Models
# Physiographic regions
# MLRA
mlra.se <- unlist(llply(mlra.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# Ecoregion
eco3.se <- unlist(llply(eco3.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# Landform
iwlf.se <- unlist(llply(iwlf.pred.p, .fun=function(x) mean(apply(x, 1, ses))))

# Geographic areas
# 9
g9.se <- unlist(llply(g9.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# 8
g8.se <- unlist(llply(g8.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# 7
g4.se <- unlist(llply(g4.pred.p, .fun=function(x) mean(apply(x, 1, ses))))

# Global model applied to each region
# Physiographic regions
# MLRA
mlra.g.se <- unlist(llply(mlra.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# Ecoregion
eco3.g.se <- unlist(llply(eco3.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# Landform
iwlf.g.se <- unlist(llply(iwlf.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))

# Geographic regions 
# 9
g9.g.se <- unlist(llply(g9.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# 8
g8.g.se <- unlist(llply(g8.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
# 4
g4.g.se <- unlist(llply(g4.m2.pred.p, .fun=function(x) mean(apply(x, 1, ses))))
```

Formatting for shannon's entropy plotting
```{r}
# Physiographic
# MLRA
# Regional 
mlra.seR <- as.data.frame(cbind(mlra.se, rep('Regional', length(mlra.se))))
names(mlra.seR) <- c('Entropy', 'ModelType')
mlra.seR$Entropy <- as.numeric(as.character(mlra.seR$Entropy))
mlra.seR$.id <- c("Great Salt Lake Area",  
                  "Mojave Desert",
                  'Cool Central Desertic Basins and Plateaus',
                  'Warm Central Desertic Basins and Plateaus',
                  'Colorado Plateau',
                  'Southwestern Plateaus, Mesas, and Foothills',
                  'Central Rocky Mountains',
                  'Wasatch and Uinta Mountains',
                  'Southern Rocky Mountains')


# Global
mlra.seG <- as.data.frame(cbind(mlra.g.se, rep('Global', length(mlra.g.se))))
names(mlra.seG) <- c('Entropy', 'ModelType')
mlra.seG$Entropy <- as.numeric(as.character(mlra.seG$Entropy))
mlra.seG$.id <- c("Great Salt Lake Area",  
                  "Mojave Desert",
                  'Cool Central Desertic Basins and Plateaus',
                  'Warm Central Desertic Basins and Plateaus',
                  'Colorado Plateau',
                  'Southwestern Plateaus, Mesas, and Foothills',
                  'Central Rocky Mountains',
                  'Wasatch and Uinta Mountains',
                  'Southern Rocky Mountains')

# Ecoregion
# Regional 
eco3.seR <- as.data.frame(cbind(eco3.se, rep('Regional', length(eco3.se))))
names(eco3.seR) <- c('Entropy', 'ModelType')
eco3.seR$Entropy <- as.numeric(as.character(eco3.seR$Entropy))
eco3.seR$.id <- c('Central Basin and Range',
                  'Mojave Basin and Range',
                  'Middle Rockies',
                  'Wyoming Basin',
                  'Wasatch and Uinta Mountains',
                  'Colorado Plateaus',
                  'Southern Rockies',
                  'Arizona and New Mexico Plateau')


# Global
eco3.seG <- as.data.frame(cbind(eco3.g.se, rep('Global', length(eco3.g.se))))
names(eco3.seG) <- c('Entropy', 'ModelType')
eco3.seG$Entropy <- as.numeric(as.character(eco3.seG$Entropy))
eco3.seG$.id <- c('Central Basin and Range',
                  'Mojave Basin and Range',
                  'Middle Rockies',
                  'Wyoming Basin',
                  'Wasatch and Uinta Mountains',
                  'Colorado Plateaus',
                  'Southern Rockies',
                  'Arizona and New Mexico Plateau')


# Landform
# Regional 
iwlf.seR <- as.data.frame(cbind(iwlf.se, rep('Regional', length(iwlf.se))))
names(iwlf.seR) <- c('Entropy', 'ModelType')
iwlf.seR$Entropy <- as.numeric(as.character(iwlf.seR$Entropy))
iwlf.seR$.id <- c('Bedrock mountain',
                  'Hills',
                  'Large highland slope',
                  'Plateau, terrace, slope, plains')


# Global
iwlf.seG <- as.data.frame(cbind(iwlf.g.se, rep('Global', length(iwlf.g.se))))
names(iwlf.seG) <- c('Entropy', 'ModelType')
iwlf.seG$Entropy <- as.numeric(as.character(iwlf.seG$Entropy))
iwlf.seG$.id <- c('Bedrock mountain',
                  'Hills',
                  'Large highland slope',
                  'Plateau, terrace, slope, plains')


# Geographic
# 9
# Regional 
g9.seR <- data.frame(cbind(g9.se, rep('Regional', length(g9.se))))
names(g9.seR) <- c('Entropy', 'ModelType')
g9.seR$Entropy <- as.numeric(as.character(g9.seR$Entropy))
g9.seR$.id <- c('1', '2', '3', '4', '5', '6', '7', '8', '9')
                                     
# Global
g9.seG <- data.frame(cbind(g9.g.se, rep('Global', length(g9.g.se))))
names(g9.seG) <- c('Entropy', 'ModelType')
g9.seG$Entropy <- as.numeric(as.character(g9.seG$Entropy))
g9.seG$.id <- c('1', '2', '3', '4', '5', '6', '7', '8', '9')

# 8
# Regional 
g8.seR <- data.frame(cbind(g8.se, rep('Regional', length(g8.se))))
names(g8.seR) <- c('Entropy', 'ModelType')
g8.seR$Entropy <- as.numeric(as.character(g8.seR$Entropy))
g8.seR$.id <- c('1', '2', '3', '4', '5', '6', '7', '8')
                                     
# Global
g8.seG <- data.frame(cbind(g8.g.se, rep('Global', length(g8.g.se))))
names(g8.seG) <- c('Entropy', 'ModelType')
g8.seG$Entropy <- as.numeric(as.character(g8.seG$Entropy))
g8.seG$.id <- c('1', '2', '3', '4', '5', '6', '7', '8')

# 4
# Regional 
g4.seR <- data.frame(cbind(g4.se, rep('Regional', length(g4.se))))
names(g4.seR) <- c('Entropy', 'ModelType')
g4.seR$Entropy <- as.numeric(as.character(g4.seR$Entropy))
g4.seR$.id <- c('1', '2', '3', '4')
                                     
# Global
g4.seG <- data.frame(cbind(g4.g.se, rep('Global', length(g4.g.se))))
names(g4.seG) <- c('Entropy', 'ModelType')
g4.seG$Entropy <- as.numeric(as.character(g4.seG$Entropy))
g4.seG$.id <- c('1', '2', '3', '4')

# Join regional and global dataframes
mlra.se.all <- rbind(mlra.seR, mlra.seG)
eco3.se.all <- rbind(eco3.seR, eco3.seG)
iwlf.se.all <- rbind(iwlf.seR, iwlf.seG)

g9.se.all <- rbind(g9.seR, g9.seG)
g8.se.all <- rbind(g8.seR, g8.seG)
g4.se.all <- rbind(g4.seR, g4.seG)

# Reorder the factor levels of ModelType so that it matchs the accuracy plots
mlra.se.all$ModelType <- relevel(mlra.se.all$ModelType, "Global")
eco3.se.all$ModelType <- relevel(eco3.se.all$ModelType, "Global")
iwlf.se.all$ModelType <- relevel(iwlf.se.all$ModelType, "Global")

g9.se.all$ModelType <- relevel(g9.se.all$ModelType, "Global")
g8.se.all$ModelType <- relevel(g8.se.all$ModelType, "Global")
g4.se.all$ModelType <- relevel(g4.se.all$ModelType, "Global")

```

Shannon's entropy plotting
```{r}
# Physiographic areas
pmlra.se <- 
mlra.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('MLRA') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

peco3.se <-
eco3.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('Ecoregion') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

piwlf.se <-
iwlf.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('Landform') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


# Geographic areas
pg9.se <-
g9.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('9 Geographic Areas') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())

pg8.se <-
g8.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('8 Geographic Areas') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


pg4.se <-
g4.se.all %>%
  mutate(.id = fct_reorder(.id, Entropy, .desc=TRUE)) %>%
  ggplot(aes(x=.id, y=Entropy)) +
  geom_point(aes(color=ModelType, shape=ModelType), size = 2.5) +
  geom_hline(yintercept = M2.se, linetype = 'dashed') + 
  xlab("Entropy") +
  ggtitle('4 Geographic Areas') + 
  ylim(0.4, 0.8) +
  coord_flip() +
  scale_x_discrete(labels = function(x) str_wrap(x, width = 40)) + 
  theme_bw() +
  theme(legend.position = "none", axis.title.y=element_blank(), legend.title=element_blank())


# Plot all on one figure
library(gridExtra)
library(ggpubr)
# Put all physiographic plots into one figure
ggarrange(pmlra.se, peco3.se, piwlf.se, ncol = 3, common.legend = TRUE, legend = 'right')
ggsave("Z:/UCRB/Figures/Entropy_physAll.png", height = 3.75, width = 10)

# Put all geographic plots into one figure
ggarrange(pg9.se, pg8.se, pg4.se, ncol = 3, common.legend = TRUE, legend = 'right')
ggsave("Z:/UCRB/Figures/Entropy_geoAll.png", height = 3.75)
```


4. Effect of data distribution
Is there a relelationship between accuracy metrics and the number of observations or imbalance ratio in the regional models? 

Calculate the number of training/testing observations
```{r}
# Add the number of training and validation observations used to model each region
# Physiographic region
# MLRA
n.mlra.train <- ddply(t.dc3, .(mlra_UCRB_m), nrow)
n.mlra.val   <- ddply(v.dc4, .(mlra_UCRB_m), nrow)

# Ecoregion
n.eco3.train <- ddply(t.dc3, .(us_eco_l3_m), nrow)
n.eco3.val   <- ddply(v.dc4, .(us_eco_l3_m), nrow)

# Iwahashi Landform
n.ilf.train <- ddply(t.dc3, .(iwahashiLF_m), nrow)
n.ilf.val   <- ddply(v.dc4, .(iwahashiLF_m), nrow)

# Geographic regions
# 9 areas
n.g9.train <- ddply(t.dc3, .(GeoStrat9), nrow)
n.g9.val   <- ddply(v.dc4, .(GeoStrat9), nrow)

# 8 areas
n.g8.train <- ddply(t.dc3, .(GeoStrat8), nrow)
n.g8.val   <- ddply(v.dc4, .(GeoStrat8), nrow)

# 4 areas
n.g4.train <- ddply(t.dc3, .(GeoStrat4), nrow)
n.g4.val   <- ddply(v.dc4, .(GeoStrat4), nrow)
```

Calculate the imbalance ratio: n observations of smallest class divided by n observations of largest class. 
An imbalance ratio of 0.1 indicates that the smalles class has 10% of the number of observations of the largest class (e.g., 50/500). Smaller numbers mean that the data is more imbalanced. 
```{r}
# define imbalance ratio function
ir <- function(x) min(x$Freq) / max(x$Freq)

# Calculate number of observations by class in training data
mlra.obs.by.class <- dlply(t.dc3, .(mlra_UCRB_m), function(x) as.data.frame(table(x$DepthClass)))
eco3.obs.by.class <- dlply(t.dc3, .(us_eco_l3_m), function(x) as.data.frame(table(x$DepthClass)))
iwlf.obs.by.class <- dlply(t.dc3, .(iwahashiLF_m), function(x) as.data.frame(table(x$DepthClass)))

g9.obs.by.class <- dlply(t.dc3, .(GeoStrat9), function(x) as.data.frame(table(x$DepthClass)))
g8.obs.by.class <- dlply(t.dc3, .(GeoStrat8), function(x) as.data.frame(table(x$DepthClass)))
g4.obs.by.class <- dlply(t.dc3, .(GeoStrat4), function(x) as.data.frame(table(x$DepthClass)))


# Apply function to get imbalance ratio
mlra.ir <- ldply(mlra.obs.by.class, ir)
eco3.ir <- ldply(eco3.obs.by.class, ir)
iwlf.ir <- ldply(iwlf.obs.by.class, ir)

g9.ir <- ldply(g9.obs.by.class, ir)
g8.ir <- ldply(g8.obs.by.class, ir)
g4.ir <- ldply(g4.obs.by.class, ir)

```

Format for plotting
```{r}
# Physiographic regions
# mlra
mlra.dd <- cbind(
  mlra.cm.df,
  unlist(mlra.bs), 
  unlist(mlra.se), 
  n.mlra.train[,2], 
  n.mlra.val[,2], 
  mlra.ir[,2],
  rep('MLRA', nrow(mlra.cm.df)))
names(mlra.dd)[c(10:15)] <- c('BrierScore', 'Entropy', 'ntrain', 'ntest', 'ImbalanceRatio', 'RegionType')

mlra.dd$.id <- recode(mlra.dd$.id,
 "35"= "Great Salt Lake Area",
 "38"= "Mojave Desert",
 "43"= "Northern Rocky Mountains",
 "44"= "Warm Central Desertic Basins and Plateaus",
 "45"= "Colorado Plateau",
 "46"= "Southwestern Plateaus, Mesas, and Foothills",
 "60"= "Central Rocky Mountains",
 "64"= "Wasatch and Uinta Mountains",
 "65"= "Southern Rocky Mountains")

# Ecoregion
eco3.dd <- cbind(
  eco3.cm.df,
  unlist(eco3.bs), 
  unlist(eco3.se), 
  n.eco3.train[,2], 
  n.eco3.val[,2], 
  eco3.ir[,2],
  rep('Ecoregion', nrow(eco3.cm.df)))
names(eco3.dd)[c(10:15)] <- c('BrierScore', 'Entropy', 'ntrain', 'ntest', 'ImbalanceRatio', 'RegionType')

eco3.dd$.id <- recode(eco3.dd$.id, 
"13" = "Central Basin & Range", 
"14" = "Mojave Basin & Range", 
"17" = "Middle Rockies", 
"18" = "Wyoming Basin", 
"19" = "Wasatch & Uinta Mountains", 
"20" = "Colorado Plateaus", 
"21" = "Southern Rockies", 
"22" = "Arizona & New Mexico Plateau")

# Landforms
iwlf.dd <- cbind(
  ilf.cm.df,
  unlist(iwlf.bs), 
  unlist(iwlf.se), 
  n.ilf.train[,2], 
  n.ilf.val[,2], 
  iwlf.ir[,2],
  rep('Landform', nrow(ilf.cm.df)))
names(iwlf.dd)[c(10:15)] <- c('BrierScore', 'Entropy', 'ntrain', 'ntest', 'ImbalanceRatio', 'RegionType')

iwlf.dd$.id <- recode(iwlf.dd$.id,
"1" = 'Bedrock mountain',
"2" = 'Hills',
"3" = 'Large highland slope',
"4" = 'Plateau, Terrace, Large lowland slope, Plains')
   
# # Geographic regions
# # 9
# g9.dd <- cbind(
#   g9.cm.df,
#   unlist(g9.bs), 
#   unlist(g9.se), 
#   n.g9.train[,2], 
#   n.g9.val[,2], 
#   g9.ir[,2])
# names(g9.dd)[c(10:14)] <- c('Brier Score', 'Entropy', 'n train', 'n test', 'Imbalance Ratio')
# 
# # 8
# g8.dd <- cbind(
#   g8.cm.df,
#   unlist(g8.bs), 
#   unlist(g8.se), 
#   n.g8.train[,2], 
#   n.g8.val[,2], 
#   g8.ir[,2])
# names(g8.dd)[c(10:14)] <- c('Brier Score', 'Entropy', 'n train', 'n test', 'Imbalance Ratio')
# 
# # 4
# g4.dd <- cbind(
#   g4.cm.df,
#   unlist(g4.bs), 
#   unlist(g4.se), 
#   n.g4.train[,2], 
#   n.g4.val[,2], 
#   g4.ir[,2])
# names(g4.dd)[c(10:14)] <- c('Brier Score', 'Entropy', 'n train', 'n test', 'Imbalance Ratio')

# Combine all dataframes into one
phys.dd <- rbind(mlra.dd, eco3.dd, iwlf.dd)

```

Plotting
There appears to be no relationship between the number of training/validation observations and the accuracy. This leads me to believe that there is another explanation which likely has to do with the inherent pedodiversity or variability of the area.
```{r}
# N training
nt1 <- phys.dd %>%
  ggplot(aes(x=ntrain, y=Accuracy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of training observations") +
  theme_bw()

nt2 <- phys.dd %>%
  ggplot(aes(x=ntrain, y=BrierScore)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of training observations") +
  theme_bw()

nt3 <- phys.dd %>%
  ggplot(aes(x=ntrain, y=Entropy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of training observations") +
  theme_bw()

png("./Ntraining.png")
grid.arrange(nt1, nt2, nt3, ncol=1, nrow=3)
dev.off()


# N testing
nv1 <- phys.dd %>%
  ggplot(aes(x=ntest, y=Accuracy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of testing observations") +
  theme_bw()

nv2 <- phys.dd %>%
  ggplot(aes(x=ntest, y=BrierScore)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of testing observations") +
  theme_bw()

nv3 <- phys.dd %>%
  ggplot(aes(x=ntest, y=Entropy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  xlab(" Number of testing observations") +
  theme_bw()

png("./Ntesting.png")
grid.arrange(nv1, nv2, nv3, ncol=1, nrow=3)
dev.off()

# Imbalance ratio
ir1 <- phys.dd %>%
  ggplot(aes(x=ImbalanceRatio, y=Accuracy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() + 
  theme(axis.title.x=element_blank()) +
  theme_bw()

ir2 <- phys.dd %>%
  ggplot(aes(x=ImbalanceRatio, y=BrierScore)) +
  facet_wrap(vars(RegionType))+
  geom_point() + 
  theme(axis.title.x=element_blank()) +
  theme_bw()

ir3 <- phys.dd %>%
  ggplot(aes(x=ImbalanceRatio, y=Entropy)) +
  facet_wrap(vars(RegionType)) +
  geom_point() +
  xlab("Imbalance Ratio") +
  theme_bw()

png("./ImbalanceRatio.png")
grid.arrange(ir1, ir2, ir3, ncol=1, nrow=3)
dev.off()
```


5. Geographic vs physiographic areas
5.1 Organize the data 
```{r}
# Physiographic
# MLRA
mlra.everything <- cbind(mlra.acc, mlra.bs.all, mlra.se.all)
mlra.everything2 <- mlra.everything[mlra.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
mlra.ms <- t(as.data.frame(apply(mlra.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
mlra.gp <- cbind.data.frame(mlra.ms, num=rep(9,nrow(mlra.ms)), Type=rep('Physiographic',nrow(mlra.ms)))
mlra.gp$metric <- rownames(mlra.gp)

# Ecoregion
eco3.everything <- cbind(eco3.acc, eco3.bs.all, eco3.se.all)
eco3.everything2 <- eco3.everything[eco3.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
eco3.ms <- t(as.data.frame(apply(eco3.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
eco3.gp <- cbind.data.frame(eco3.ms, num=rep(8,nrow(eco3.ms)), Type=rep('Physiographic',nrow(eco3.ms)))
eco3.gp$metric <- rownames(eco3.gp)

# Landform
iwlf.everything <- cbind(ilf.acc, iwlf.bs.all, iwlf.se.all)
iwlf.everything2 <- iwlf.everything[iwlf.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
iwlf.ms <- t(as.data.frame(apply(iwlf.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
iwlf.gp <- cbind.data.frame(iwlf.ms, num=rep(4,nrow(iwlf.ms)), Type=rep('Physiographic',nrow(iwlf.ms)))
iwlf.gp$metric <- rownames(iwlf.gp)


# Geographic 
#9 regions
g9.everything <- cbind(g9.acc, g9.bs.all, g9.se.all)
g9.everything2 <- g9.everything[g9.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
g9.ms <- t(as.data.frame(apply(g9.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
g9.gp <- cbind.data.frame(g9.ms, num=rep(9,nrow(g9.ms)), Type=rep('Geographic',nrow(g9.ms)))
g9.gp$metric <- rownames(g9.gp)

#8 regions
g8.everything <- cbind(g8.acc, g8.bs.all, g8.se.all)
g8.everything2 <- g8.everything[g8.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
g8.ms <- t(as.data.frame(apply(g8.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
g8.gp <- cbind.data.frame(g8.ms, num=rep(8,nrow(g8.ms)), Type=rep('Geographic',nrow(g8.ms)))
g8.gp$metric <- rownames(g8.gp)

#4 regions
g4.everything <- cbind(g4.acc, g4.bs.all, g4.se.all)
g4.everything2 <- g4.everything[g4.everything$ModelType=='Regional',]
# Calculate mean and standard deviation
g4.ms <- t(as.data.frame(apply(g4.everything2[,c(2,10,13)], 2, function (x) { c(mean = mean(x), sd = sd(x)) })))
# Add num (number of classes num) and type (geographic or physiographic)
g4.gp <- cbind.data.frame(g4.ms, num=rep(4,nrow(g4.ms)), Type=rep('Geographic',nrow(g4.ms)))
g4.gp$metric <- rownames(g4.gp)

# Join all accuracy metrics together
gp.all <- rbind(mlra.gp, eco3.gp, iwlf.gp, g9.gp, g8.gp, g4.gp)
gp.all$num <- as.factor(gp.all$num)

gp.all$metric <- as.factor(gp.all$metric)
levels(gp.all$metric) = c('Accuracy', 'Brier Score', 'Entropy')

```

5.2 Plotting
```{r}
# Global model accuracy, brier scores, and entorpy to add to plot
Z = as.data.frame(rbind(M2.cm$overall[1], M2.bs, M2.se))
Z$metric <- c('Accuracy', 'BrierScore', 'Entropy')


ggplot(data = gp.all, 
  aes(x=num, y=mean, color = Type)) + 
  geom_point(position=position_dodge(width=0.5)) +
  xlab('Number of physiographic or geographic regions') +
  ylab('') +
  geom_errorbar(aes(ymin=mean-sd, ymax=mean+sd), position=position_dodge(width=0.5), width=0.25) + 
  facet_grid(~metric) +
  geom_hline(data=Z, aes(yintercept = Accuracy), linetype = 'dashed') +
  theme_bw() 

ggsave("./phys_vs_geog.png", height = 2.5)
```


6. Compare Global model vs. combining models into one supra-regional model. 
A function to combine random forest models. 
https://stackoverflow.com/questions/19170130/combining-random-forests-built-with-different-training-sets-in-r
```{r combine randomForest models}
my_combine <- function (...) 
{
    pad0 <- function(x, len) c(x, rep(0, len - length(x)))
    padm0 <- function(x, len) rbind(x, matrix(0, nrow = len - 
        nrow(x), ncol = ncol(x)))
    rflist <- list(...)
    areForest <- sapply(rflist, function(x) inherits(x, "randomForest"))
    if (any(!areForest)) 
        stop("Argument must be a list of randomForest objects")
    rf <- rflist[[1]]
    classRF <- rf$type == "classification"
    trees <- sapply(rflist, function(x) x$ntree)
    ntree <- sum(trees)
    rf$ntree <- ntree
    nforest <- length(rflist)
    haveTest <- !any(sapply(rflist, function(x) is.null(x$test)))
    vlist <- lapply(rflist, function(x) rownames(importance(x)))
    numvars <- sapply(vlist, length)
    if (!all(numvars[1] == numvars[-1])) 
        stop("Unequal number of predictor variables in the randomForest objects.")
    for (i in seq_along(vlist)) {
        if (!all(vlist[[i]] == vlist[[1]])) 
            stop("Predictor variables are different in the randomForest objects.")
    }
    haveForest <- sapply(rflist, function(x) !is.null(x$forest))
    if (all(haveForest)) {
        nrnodes <- max(sapply(rflist, function(x) x$forest$nrnodes))
        rf$forest$nrnodes <- nrnodes
        rf$forest$ndbigtree <- unlist(sapply(rflist, function(x) x$forest$ndbigtree))
        rf$forest$nodestatus <- do.call("cbind", lapply(rflist, 
            function(x) padm0(x$forest$nodestatus, nrnodes)))
        rf$forest$bestvar <- do.call("cbind", lapply(rflist, 
            function(x) padm0(x$forest$bestvar, nrnodes)))
        rf$forest$xbestsplit <- do.call("cbind", lapply(rflist, 
            function(x) padm0(x$forest$xbestsplit, nrnodes)))
        rf$forest$nodepred <- do.call("cbind", lapply(rflist, 
            function(x) padm0(x$forest$nodepred, nrnodes)))
        tree.dim <- dim(rf$forest$treemap)
        if (classRF) {
            rf$forest$treemap <- array(unlist(lapply(rflist, 
                function(x) apply(x$forest$treemap, 2:3, pad0, 
                  nrnodes))), c(nrnodes, 2, ntree))
        }
        else {
            rf$forest$leftDaughter <- do.call("cbind", lapply(rflist, 
                function(x) padm0(x$forest$leftDaughter, nrnodes)))
            rf$forest$rightDaughter <- do.call("cbind", lapply(rflist, 
                function(x) padm0(x$forest$rightDaughter, nrnodes)))
        }
        rf$forest$ntree <- ntree
        if (classRF) 
            rf$forest$cutoff <- rflist[[1]]$forest$cutoff
    }
    else {
        rf$forest <- NULL
    }
    #
    #Tons of stuff removed here...
    #
    if (classRF) {
        rf$confusion <- NULL
        rf$err.rate <- NULL
        if (haveTest) {
            rf$test$confusion <- NULL
            rf$err.rate <- NULL
        }
    }
    else {
        rf$mse <- rf$rsq <- NULL
        if (haveTest) 
            rf$test$mse <- rf$test$rsq <- NULL
    }
    rf
}
```

Try out the my_combine function, then make predictions. 
```{r}
library(randomForest)
#MLRAs
mlra.all <- my_combine(c.mlra[[1]]$finalModel, 
                     c.mlra[[2]]$finalModel,
                     c.mlra[[3]]$finalModel,
                     c.mlra[[4]]$finalModel,
                     c.mlra[[5]]$finalModel,
                     c.mlra[[6]]$finalModel,
                     c.mlra[[7]]$finalModel,
                     c.mlra[[8]]$finalModel,
                     c.mlra[[9]]$finalModel)

# Predict validation data and create confusion matrix
mlra.all.pred <- predict(mlra.all, newdata = v.dc4)
mlra.all.cm <- confusionMatrix(data=mlra.all.pred, reference = v.dc4$DepthClass)

# Ecoregion
eco3.all <- my_combine(c.eco3[[1]]$finalModel, 
                       c.eco3[[2]]$finalModel,
                       c.eco3[[3]]$finalModel,
                       c.eco3[[4]]$finalModel,
                       c.eco3[[5]]$finalModel,
                       c.eco3[[6]]$finalModel,
                       c.eco3[[7]]$finalModel,
                       c.eco3[[8]]$finalModel)

# Predict validation data and create confusion matrix
eco3.all.pred <- predict(eco3.all, newdata = v.dc4)
eco3.all.cm <- confusionMatrix(data=eco3.all.pred, reference = v.dc4$DepthClass)


#Landform
iwlf.all <- my_combine(c.iwlf[[1]]$finalModel, 
                       c.iwlf[[2]]$finalModel,
                       c.iwlf[[3]]$finalModel,
                       c.iwlf[[4]]$finalModel)

# Predict validation data and create confusion matrix
iwlf.all.pred <- predict(iwlf.all, newdata = v.dc4)
iwlf.all.cm <- confusionMatrix(data=iwlf.all.pred, reference = v.dc4$DepthClass)
```

The following comprision reveals that the global model is more accurate than the combined regional models (mostly there is a decrease in the sensitivity (ability to predict 'present') compared to the global model). Thus if a regional modeling approach is used then attempting to join regional predictions to avoid 'county boundary issues' combining regional models is insufficeint. 

Compare validation accuracy of global model vs regional models 
```{r}
# Global model
M2.cm
# Global models composed of all regional models
mlra.all.cm
eco3.all.cm
iwlf.all.cm

# Combine accuracy measures into a table
acc.all <- as.data.frame(rbind(
M2.cm$overall[c(3,1,4)],
mlra.all.cm$overall[c(3,1,4)],
eco3.all.cm$overall[c(3,1,4)],
iwlf.all.cm$overall[c(3,1,4)]))

# Give good names
ModelType <- c('Global', 'MLRA', 'Ecoregion', 'Landform')
acc.all$Model <- factor(ModelType, levels = c('Global', 'MLRA', 'Ecoregion', 'Landform'), ordered=TRUE)

# Save to a .csv for presentation
#write.csv(acc.all, "Z:/UCRB/Figures/Combined_model_accuracy.csv")


# Make nice plots
ggplot(acc.all, aes(x=Model, y=Accuracy)) + 
  geom_point()+
  geom_errorbar(aes(ymin=AccuracyLower, ymax=AccuracyUpper), width=.05) +
  xlab('Combined Model') + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationAccuracy_combined models.png", height=1.25, width=3)
```


7. Predictions
7.1 Set up covariates to make predictions.
```{r}
library(raster)

# List all .tif files (all possible covariates) 
fil.tif <- list.files(path = "Z:/UCRB/Covariates", pattern = ".tif$", recursive = TRUE, full.names=TRUE)

# Subset list of all covariates for only those that were selected by the model (the predictors() function gets the variable names from each model)
covs <- grep(paste(predictors(M2), collapse="|"), fil.tif, value=TRUE)

# I made the 'mistake' of renaming "upland_valley.bottom_and_lowland_sedimentary_deposit_thickness_m" to "SDT" in my training matrix, so I need to add this manually. Then rename
covs2 <- c(covs, "Z:/UCRB/Covariates/PelletierCovariates/upland_valley-bottom_and_lowland_sedimentary_deposit_thickness_m.tif")

# Create a raster stack for predictions
Mpred <- stack(covs2)


# For reasons entirely unclear the above raster stack duplicates a number of covariates and names the original and duplicates with .1 & .2 extensions. Fix this. also rename the SDT layer to match what is in model.
Mpred1 <- dropLayer(Mpred, grep("m.2", names(Mpred)))
names(Mpred1) <- gsub(".1$", "", names(Mpred1))
names(Mpred1) <- gsub("upland_valley.bottom_and_lowland_sedimentary_deposit_thickness_m$", "SDT", names(Mpred1))

#writeRaster(Mpred1, "Z:/UCRB/Covariates/Mpred1.tif")
```

7.2 Make predictions using the global model (without land class covariates) that was built using all observations. 
```{r}
rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()

raster::predict(object=Mpred1, model=M2.allobs, progress="text", filename = 'Z:/UCRB/Predictions/M2_allobs.tif', datatype = 'INT1U', options=c("COMPRESS=LZW"))

raster::predict(object=Mpred1, model=M2.allobs, index = 1:6, type = 'prob', progress="text", filename = 'Z:/UCRB/Predictions/M2_prob_allobs.tif', datatype = 'FLT4S', options=c("COMPRESS=LZW"))

endCluster()
Sys.time()
```

7.3 Make predictions by area.
This takes 22 days. This must be parallized on the HPC. 
I suppose that this would be faster if I could parallize the following code to make predictions from each regional model on a different processor. Right now the code serializes regional model predictions but uses all available cores/threads to make the predictions. I could drop the processing time to only the time it takes to make predictions for one model, but this would require a computer with multiple processors (with multiple cores per processor). I suppose that I could try to parallize this code to run each prediction on a single core, but I don't know how this would work with memory... I recall trying the clusterR function (in the R package like Travis uses), but it didn't work, and I think that I remember this was because clusterR didn't work on a virtual machine. 

# Save only objects needed for HPC computing. Includes models and raster stack. 
save(Mpred1, obs3.eco3, file="Z:/UCRB/Models/hpc_predict.Rdata")

7.3.1 MLRA
```{r}
# rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
# Sys.time()
# beginCluster()
# some mlra's finished before running out of ram 1:length(c.mlra), so split into two runs.)

 # for (i in 1:4)  {
 # raster::predict(object=Mpred1, model=c.mlra[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra', names(c.mlra)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
 # }

 # for (i in 1:4) {
 # raster::predict(object=Mpred1, model=c.mlra[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra',names(c.mlra)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
 # }



# beginCluster()
# Sys.time()
# 
#  for (i in 5:9)  {
#  raster::predict(object=Mpred1, model=c.mlra[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra', names(c.mlra)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
#  }
# 
#  for (i in 5:9) {
#  raster::predict(object=Mpred1, model=c.mlra[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'mlra',names(c.mlra)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
#  }
# 
# 
# endCluster()
# Sys.time()
# gc()
```

7.3.2 Ecoregion. wrapping a gc() call in the function throws an error, but seems to work and keep memory usage stable. Each probability prediction takes about 15.6 hours.  
```{r}
# rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
# Sys.time()
# beginCluster()

# for (i in 1:length(c.eco3)) {
#  print(names(c.eco3)[1])
#  raster::predict(object=Mpred1, model=c.eco3[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'eco3', names(c.eco3)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
#   gc()
#  }
# 
# for (i in 1:length(c.eco3)) {
#   print(names(c.eco3)[1])
#  raster::predict(object=Mpred1, model=c.eco3[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'eco3', names(c.eco3)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
#   gc()
# }

# remove all objects except those that I need to make predicitions to increase available memory so it goes faster
# rm(list=ls()[!(ls() %in% c('Mpred1','c.eco3'))])

# rasterOptions(maxmemory = 1e+12, chunksize = 1e+7, timer = TRUE)
# beginCluster()
# raster::predict(object=Mpred1, model=c.eco3[8], index = 1:6, type = 'prob', progress="text", filename = 'Z:/UCRB/Predictions/phy_area/eco322_prob.tif', datatype = 'FLT4S', options=c("COMPRESS=LZW"))
# endCluster()


# endCluster()
# Sys.time()
gc()
```

7.3.3 Iwahashi Landform
```{r}
# rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
# Sys.time()
# beginCluster()
# 
# for (i in 1:length(c.iwlf)) {
#  raster::predict(object=Mpred1, model=c.iwlf[i], progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'iwlf', names(c.iwlf)[i], '.tif'), datatype = 'INT1U', options=c("COMPRESS=LZW"))
# }
# 
#  for (i in 1:length(c.iwlf)) {
#  raster::predict(object=Mpred1, model=c.iwlf[i], index = 1:6, type = 'prob', progress="text", filename = paste0('Z:/UCRB/Predictions/phy_area/', 'iwlf', names(c.iwlf)[i], '_prob','.tif'), datatype = 'FLT4S', options=c("COMPRESS=LZW"))
#  }
# 
# endCluster()
# Sys.time()
# gc()
```

Time to run all predictions for all three land classifications: 
(59025+61179+56601+59259+44684+46612+41673+43784+57100+54903+56536+57084+56608+42200+40377+41914+42004+41076+46439+43450+40921+45464+40996+40982+42082+42749+61042+56524+56743+57504+58391+50505+65186+57334+62904+59956+57055)/3600
~ 525 hours or about 22 days. 32 GB RAM, using 31 processors. 

Save for when things crash
```{r}
#save.image("Z:/UCRB/Models/byPhysiographicArea 10.20.19.Rdata")
```


8. Regional spatial ensemble modeling. 
I can't use the ensemble methods in Malone et al., because this is categorical data. Though it seems feasible that I could somehow derive weights from some type of multinomial logistic regression.  

Extract the max probability from each probability stack
```{r}
rasterOptions(timer=TRUE, progress='text')
# # MLRA regions takes about 5 min to run 
# fmlra <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "mlra(.*)_prob.tif", full.names=T)
#  
# beginCluster(32)
#  clusterR(stack(fmlra[1]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[1]), "_max.tif"))
#  clusterR(stack(fmlra[2]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[2]), "_max.tif"))
#  clusterR(stack(fmlra[3]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[3]), "_max.tif"))
#  clusterR(stack(fmlra[4]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[4]), "_max.tif"))
#  clusterR(stack(fmlra[5]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[5]), "_max.tif"))
#  clusterR(stack(fmlra[6]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[6]), "_max.tif"))
#  clusterR(stack(fmlra[7]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[7]), "_max.tif"))
#  clusterR(stack(fmlra[8]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[8]), "_max.tif"))
#  clusterR(stack(fmlra[9]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/mlra",gsub("[^0-9]", "",  fmlra[9]), "_max.tif"))
# endCluster()
# 
# # Ecoregion
# feco3 <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)_prob.tif", full.names=T)
# 
# beginCluster(32)
#  clusterR(stack(feco3[1]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[1]), "_max.tif"))
#  clusterR(stack(feco3[2]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[2]), "_max.tif"))
#  clusterR(stack(feco3[3]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[3]), "_max.tif"))
#  clusterR(stack(feco3[4]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[4]), "_max.tif"))
#  clusterR(stack(feco3[5]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[5]), "_max.tif"))
#  clusterR(stack(feco3[6]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[6]), "_max.tif"))
#  clusterR(stack(feco3[7]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[7]), "_max.tif"))
#  clusterR(stack(feco3[8]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/eco",gsub("[^0-9]", "",  feco3[8]), "_max.tif"))
# endCluster()
# 
# # Landform
# fiwlf <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "iwlf(.*)_prob.tif", full.names=T)
# 
# beginCluster(32)
#  clusterR(stack(fiwlf[1]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/iwlf",gsub("[^0-9]", "",  fiwlf[1]), "_max.tif"))
#  clusterR(stack(fiwlf[2]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/iwlf",gsub("[^0-9]", "",  fiwlf[2]), "_max.tif"))
#  clusterR(stack(fiwlf[3]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/iwlf",gsub("[^0-9]", "",  fiwlf[3]), "_max.tif"))
#  clusterR(stack(fiwlf[4]), calc, args=list(max, na.rm=T), filename= paste0("Z:/UCRB/Predictions/phy_area/iwlf",gsub("[^0-9]", "",  fiwlf[4]), "_max.tif"))
# endCluster()

```

Stack max probabilities from each model, then get overall max probability and which.max 
```{r}
rasterOptions(timer = T, progress='text')
# List the max of the regional models and add the global model
mlramax <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "mlra(.*)[^_overall_which]_max", full.names=T)
eco3max <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)[^_overall_which]_max", full.names=T)
iwlfmax <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "iwlf(.*)[^_overall_which]_max", full.names=T)

# Calculate the overall max (from the stack of all the max values from each model). Takes ~ 6 min each
# I'm calling this prediction uncertainty
beginCluster()
 clusterR(raster::stack(mlramax), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/mlra_predConf.tif")
 clusterR(raster::stack(eco3max), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/eco3_predConf.tif")
 clusterR(raster::stack(iwlfmax), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/iwlf_predConf.tif")
endCluster()

# Which raster layer has the highest prediction. Takes < 12 min each.
# Define this function to deal with na's
# https://stackoverflow.com/questions/12452549/implementing-which-max-on-an-r-rasterstack-for-each-cell
which.max2 <- function(x, ...) ifelse(length(x) ==sum(is.na(x) ), NA, which.max(x)) 

beginCluster()
 clusterR(raster::stack(mlramax), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/mlra_which_max.tif", datatype = 'INT1U')
 clusterR(raster::stack(eco3max), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/eco3_which_max.tif", datatype = 'INT1U')
 clusterR(raster::stack(iwlfmax), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/iwlf_which_max.tif", datatype = 'INT1U')
endCluster()
```

Reduce the stack of class predictions to a single class map based on which model predicted the highest probability. There is probably a way to do this with just the probability values, which would reduce the need to make class predictions, but this works for now
```{r}
rasterOptions(timer = TRUE, progress = 'text', maxmemory=1e+08) # Reducing memory to +08 makes it run on 32 GB ram

# Define function that choses the cell value from the layer identified in the first layer. 
# By making the which.max layer the first layer, I can then just index by this position as the raster calc() function operates by turning each cell stack into a vector. 
maxClass <- function(x) x[2:length(x)][x[1]]

# vector of file names
mlra.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "mlra(.*)[^_prob_max_classPred_predConf].tif", full.names=T)
eco3.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)[^_prob_max_classPred_predConf].tif", full.names=T)
iwlf.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "iwlf(.*)[^_prob_max_classPred_predConf].tif", full.names=T)


# Load the which.max rasters (by reloading the rasters I avoid any cluster errors if I have called gc())
mlra.wm <- raster("Z:/UCRB/Predictions/phy_area/mlra_which_max.tif")
eco3.wm <- raster("Z:/UCRB/Predictions/phy_area/eco3_which_max.tif")
iwlf.wm <- raster("Z:/UCRB/Predictions/phy_area/iwlf_which_max.tif")

# raster stacks
mlra.cs <- stack(mlra.wm, stack(mlra.fc))
eco3.cs <- stack(eco3.wm, stack(eco3.fc))
iwlf.cs <- stack(iwlf.wm, stack(iwlf.fc))


# Ensemble model final class predictions. 
# Takes about 10 min for the maxClass function and 5 min to write to file. This process is so memory intensive that I have to wrap each one in it's own cluster to release the RAM between runs.
beginCluster()
 clusterR(mlra.cs, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/mlra_ensemble_classPred.tif", datatype = 'INT1U')
endCluster()
gc()

beginCluster()
 clusterR(eco3.cs, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/eco3_ensemble_classPred.tif", datatype = 'INT1U')
endCluster()
gc()

beginCluster()
 clusterR(iwlf.cs, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/iwlf_ensemble_classPred.tif", datatype = 'INT1U')
endCluster()
gc()

# # Test of maxClass function
# elem = c(1, 15,5,4,3,6,5,5,5,6,6)
# maxClass(elem)
# 
# elem = c(6, 15,5,4,3,6,11,5,5,6)
#  maxClass(elem)

```



9. Global + regional spatial ensemble modeling.
This improves accuracy by about 1%, but it is worth the little bit of extra overhead. 

Calculate global model max, then stack max probabilities from each model, then get overall max probability and which.max 
```{r}
rasterOptions(timer = T, progress='text')

# Global model
beginCluster(32)
 clusterR(stack("Z:/UCRB/Predictions/M2_prob.tif"), calc, args=list(max, na.rm=T), filename= "Z:/UCRB/Predictions/M2_max.tif")
endCluster()

# List the max of the regional models and add the global model
mlramax <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "mlra(.*)[^which]_max", full.names=T)
mlramax2 <- c("Z:/UCRB/Predictions/M2_max.tif", mlramax)
print(mlramax2)

eco3max <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)[^which]_max", full.names=T)
eco3max2 <- c("Z:/UCRB/Predictions/M2_max.tif", eco3max)
print(eco3max2)

iwlfmax <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "iwlf(.*)[^which]_max", full.names=T)
iwlfmax2 <- c("Z:/UCRB/Predictions/M2_max.tif", iwlfmax)
print(iwlfmax2)

# Calculate the overall max (from the stack of all the max values from each model)
# I'm calling this prediction confidence
beginCluster()
 clusterR(raster::stack(mlramax2), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/mlra_predConf_GR.tif")
 clusterR(raster::stack(eco3max2), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/eco3_predConf_GR.tif")
 clusterR(raster::stack(iwlfmax2), calc, args=list(max, na.rm=T), filename = "Z:/UCRB/Predictions/phy_area/iwlf_predConf_GR.tif")
endCluster()

# Which raster layer has the highest prediction.
# Define this function to deal with na's
# https://stackoverflow.com/questions/12452549/implementing-which-max-on-an-r-rasterstack-for-each-cell
which.max2 <- function(x, ...) ifelse(length(x) ==sum(is.na(x) ), NA, which.max(x)) 

beginCluster()
 clusterR(raster::stack(mlramax2), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/mlra_which_max_GR.tif", datatype = 'INT1U')
 clusterR(raster::stack(eco3max2), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/eco3_which_max_GR.tif", datatype = 'INT1U')
 clusterR(raster::stack(iwlfmax2), calc, args=list(which.max2), filename = "Z:/UCRB/Predictions/phy_area/iwlf_which_max_GR.tif", datatype = 'INT1U')
endCluster()
```

Reduce the stack of class predictions to a single class map based on which model predicted the highest probability.
```{r}
rasterOptions(timer = TRUE, progress = 'text', maxmemory=1e+08) # Reducing memory to +08 makes it run on 32 GB ram

# Define function that choses the cell value from the layer identified in the first layer. 
# By making the which.max layer the first layer, I can then just index by this position 
# as the raster calc() function operates by turning each cell stack into a vector. 
maxClass <- function(x) x[2:length(x)][x[1]]

# vector of file names of class predictions
mlra.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "mlra(.*)[^_prob_max_GR_predConf].tif", full.names=T)
mlra.fc2<- c("Z:/UCRB/Predictions/M2.tif", mlra.fc)
print(mlra.fc2)

eco3.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)[^_prob_max_GR_predConf].tif", full.names=T)
eco3.fc2<- c("Z:/UCRB/Predictions/M2.tif", eco3.fc)
print(eco3.fc2)

iwlf.fc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "iwlf(.*)[^_prob_max_GR_predConf].tif", full.names=T)
iwlf.fc2 <- c("Z:/UCRB/Predictions/M2.tif", iwlf.fc)
print(iwlf.fc2)

# Load the which.max rasters
mlra.wm.GR <- raster("Z:/UCRB/Predictions/phy_area/mlra_which_max_GR.tif")
eco3.wm.GR <- raster("Z:/UCRB/Predictions/phy_area/eco3_which_max_GR.tif")
iwlf.wm.GR <- raster("Z:/UCRB/Predictions/phy_area/iwlf_which_max_GR.tif")

# raster stacks
mlra.cs.GR <- stack(mlra.wm.GR, stack(mlra.fc2))
eco3.cs.GR <- stack(eco3.wm.GR, stack(eco3.fc2))
iwlf.cs.GR <- stack(iwlf.wm.GR, stack(iwlf.fc2))


# Ensemble model final class predictions. 
# Takes about 10 min for the maxClass function and 5 min to write to file. This process is so memory intensive that I have to wrap each one in it's own cluster to release the RAM between runs.
beginCluster()
clusterR(mlra.cs.GR, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/mlra_ensemble_classPred_GR.tif", datatype = 'INT1U')
endCluster()
gc()

beginCluster()
 clusterR(eco3.cs.GR, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/eco3_ensemble_classPred_GR.tif", datatype = 'INT1U')
endCluster()
 gc()
 
beginCluster()
 clusterR(iwlf.cs.GR, calc, args=list(maxClass), filename = "Z:/UCRB/Predictions/phy_area/iwlf_ensemble_classPred_GR.tif", datatype = 'INT1U')
endCluster()
gc()

# # Test of maxClass function
# elem = c(1, 15,5,4,3,6,5,5,5,6,6)
# maxClass(elem)
# 
# elem = c(6, 15,5,4,3,6,11,5,5,6)
#  maxClass(elem)
```


# Ecoregion
# 1       Global
# 2 "13" "Central Basin and Range" 
# 3 "14" "Mojave Basin and Range" 
# 4 "17" "Middle Rockies" 
# 5 "18" "Wyoming Basin" 
# 6 "19" "Wasatch and Uinta Mountains" 
# 7 "20" "Colorado Plateaus" 
# 8 "21" "Southern Rockies" 
# 9 "22" "Arizona/New Mexico Plateau"


Validate final class map from the prediction ensemble. 
Wow this really improves accuracy (up to 21%)
```{r}
# Load validation observations
v.dc3 <- read.csv("Z:/UCRB/Observations/v.dc3.csv")
v.dc3$DepthClass <- factor(v.dc3$DepthClass, levels = c('BR','VS','S','MD','D','VD'), ordered=TRUE)

# Make validation locations into spatialpointsdataframe
coordinates(v.dc3) <- ~X+Y
proj4string(v.dc3) <- CRS("+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs")

# Regional only ensemble predictions
mlra_ensemble_classPred <- raster("Z:/UCRB/Predictions/phy_area/mlra_ensemble_classPred.tif")
eco3_ensemble_classPred <- raster("Z:/UCRB/Predictions/phy_area/eco3_ensemble_classPred.tif")
iwlf_ensemble_classPred <- raster("Z:/UCRB/Predictions/phy_area/iwlf_ensemble_classPred.tif")

# Global + regional (GR) ensemble predictions
mlra_ensemble_classPred.GR <- raster("Z:/UCRB/Predictions/phy_area/mlra_ensemble_classPred_GR.tif")
eco3_ensemble_classPred.GR <- raster("Z:/UCRB/Predictions/phy_area/eco3_ensemble_classPred_GR.tif")
iwlf_ensemble_classPred.GR <- raster("Z:/UCRB/Predictions/phy_area/iwlf_ensemble_classPred_GR.tif")

# Extract prediction values at validation locations
m.ens.v <- as.factor(as.character(raster::extract(mlra_ensemble_classPred, v.dc3)))
e.ens.v <- as.factor(as.character(raster::extract(eco3_ensemble_classPred, v.dc3)))
l.ens.v <- as.factor(as.character(raster::extract(iwlf_ensemble_classPred, v.dc3)))

m.ens.v.gr <- as.factor(as.character(raster::extract(mlra_ensemble_classPred.GR, v.dc3)))
e.ens.v.gr <- as.factor(as.character(raster::extract(eco3_ensemble_classPred.GR, v.dc3)))
l.ens.v.gr <- as.factor(as.character(raster::extract(iwlf_ensemble_classPred.GR, v.dc3)))

# Recode to match predictions
m.ens.v <- dplyr::recode(m.ens.v, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')
e.ens.v <- dplyr::recode(e.ens.v, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')
l.ens.v <- dplyr::recode(l.ens.v, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')

m.ens.v.gr <- dplyr::recode(m.ens.v.gr, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')
e.ens.v.gr <- dplyr::recode(e.ens.v.gr, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')
l.ens.v.gr <- dplyr::recode(l.ens.v.gr, '1'='BR','2'='VS','3'='S','4'='MD','5'='D','6'='VD')


# Confusion matrix
m.cm   <- caret::confusionMatrix(m.ens.v, v.dc3$DepthClass)
m.cm.gr<- caret::confusionMatrix(m.ens.v.gr, v.dc3$DepthClass)

e.cm   <- caret::confusionMatrix(e.ens.v, v.dc3$DepthClass)
e.cm.gr<- caret::confusionMatrix(e.ens.v.gr, v.dc3$DepthClass)

i.cm   <- caret::confusionMatrix(l.ens.v, v.dc3$DepthClass)
i.cm.gr<- caret::confusionMatrix(l.ens.v.gr, v.dc3$DepthClass)


# Key to interpreting the confusion matrix: 
#  Prevelance: the proportion of the test observations in the class
#  Sensitivity: How often did the model predict the true class
#  Specificity: How often did the model preict the wrong class as the true class
#  Positive predicted value: sensitivity, but adjusted for prevelance. The probability that the sample is an event. 
#  Negative predicted value: specificicty, but adjusted for prevelance.
#  Detection rate: the correctly predicted class (that was the class) compared to all other classes. - I'm not sure this is really useful. 
#  Detection Prevalance - All the predicted (right and wrong) divided by all the other classes. 
#  Balanced Accuracy - The average of sensitivity and specificity. Should be high. 
```


Regional ensemble accuracy plotting. 
```{r}
es.acc.all <- as.data.frame(rbind(
m.cm$overall[c(3,1,4)],
m.cm.gr$overall[c(3,1,4)],
e.cm$overall[c(3,1,4)],
e.cm.gr$overall[c(3,1,4)],
i.cm$overall[c(3,1,4)],
i.cm.gr$overall[c(3,1,4)]))

# Give good names
ModelType2 <- rep(c('MLRA', 'Ecoregion', 'Landform'), each = 2)
EnsembleType <-rep(c('Regional Only', 'Regional + Global'), times=3)

es.acc.all$Model <- factor(ModelType2, levels = c('MLRA', 'Ecoregion', 'Landform'), ordered=TRUE)
es.acc.all$EnsembleType <- factor(EnsembleType, levels = c('Regional Only', 'Regional + Global'), ordered=TRUE)


# Make nice plots
ggplot(es.acc.all, aes(x=Model, y=Accuracy, color=EnsembleType)) + 
  geom_point(position = position_dodge(width = .5)) + 
  geom_errorbar(aes(ymin=AccuracyLower, ymax=AccuracyUpper), width=.15, position = position_dodge(width = .5)) +
  geom_hline(yintercept=M2.cm$overall[1], linetype="dashed") +
  ylim(0.6, 0.95) + 
  theme_bw() + 
  theme(axis.title.x=element_blank()) + 
  scale_color_manual(values=c("#F8766D", "#00BFC4"))

ggsave("Z:/UCRB/Figures/ValidationAccuracy_combined models.png", height=2.3, width=4.5)


# Great way to find ggplot2 default colors
#library(scales)
#show_col(hue_pal()(2))

```


Prediction confidence of each ensemble prediction (only going with global + regional)
```{r}
rasterOptions(timer = TRUE, progress = 'text', maxmemory=1e+09)
# Load prediction confidence
m.pred.conf <- raster("Z:/UCRB/Predictions/phy_area/mlra_predConf_GR.tif")
e.pred.conf <- raster("Z:/UCRB/Predictions/phy_area/eco3_predConf_GR.tif")
i.pred.conf <- raster("Z:/UCRB/Predictions/phy_area/iwlf_predConf_GR.tif")

# Calculate mean and standard deviation of prediction confidcence
mpc.mean <- cellStats(m.pred.conf, stat = 'mean')
mpc.sd <- cellStats(m.pred.conf, stat = 'sd')

epc.mean <- cellStats(e.pred.conf, stat = 'mean')
epc.sd <- cellStats(e.pred.conf, stat = 'sd')

ipc.mean <- cellStats(i.pred.conf, stat = 'mean')
ipc.sd <- cellStats(i.pred.conf, stat = 'sd')

# combine and plot
stats.all <- 
data.frame(cbind(
c('MLRA', 'Ecoregion', 'Landform'),
c(mpc.mean, epc.mean, ipc.mean),
c(mpc.sd, epc.sd, ipc.sd)))

names(stats.all) <- c('Region', 'Mean', 'SD')
stats.all$Region <- factor(stats.all$Region, levels = c('MLRA', 'Ecoregion', 'Landform'))
stats.all$Mean<- as.numeric(as.character(stats.all$Mean))
stats.all$SD  <- as.numeric(as.character(stats.all$SD))


ggplot(stats.all, aes(x=Region, y=Mean)) + 
  geom_point() + 
  geom_errorbar(aes(ymin=Mean-SD, ymax=Mean+SD), width=.09) +
  ylim(0.2, 0.8) + 
  theme_bw() + 
  theme(axis.title.x=element_blank()) + 
  ylab('Prediction Confidence') 

ggsave("Z:/UCRB/Figures/predictionConfidence.png", height=2.3, width=4.5)

#save.image('Z:/UCRB/Models/byPhysiographicArea 12.11.19.RData')

```




I should repredict with all the values to get the best maps then rerun the ensemble stack. I will do after the paper goes to publication.  




MISC: 
Things I tried that either 1) didn't work or 2) were not relevant for the paper. 

Here is how to get the ggplot colors. I used this for the color scheme for the which.max rasters to match what I did in the regional figures. 
```{r}
# https://intellipaat.com/community/12228/emulate-ggplot2-default-color-palette
gg_color <- function(n) {
  hues = seq(15, 375, length = n + 1)
  hcl(h = hues, l = 65, c = 100)[1:n]
}

gg_color(9)
#"#F8766D" "#D39200" "#93AA00" "#00BA38" "#00C19F" "#00B9E3" "#619CFF" "#DB72FB" "#FF61C3"
gg_color(8)
#"#F8766D" "#CD9600" "#7CAE00" "#00BE67" "#00BFC4" "#00A9FF" "#C77CFF" "#FF61CC"
gg_color(4)
#"#F8766D" "#7CAE00" "#00BFC4" "#C77CFF"
```



M1.
Brier scores and Entropy for the prediction ensemble. 
Can't calculate because I need a probability prediction for each class, not just the max class... I could calculate this, but it would be fairly complicated to produce because I would need to use the raster which identifies which model each predicted cell came from, then extract the coresponding probabilities. This would involve to much computational overhead for the return I would get, but I think it would be super cool and probably show that the regional-ensemble would make much better predictions because looking at the probabilities they are much higher. 
```{r}
# For Brier and Entropy I need probability of predictions so I need to extract from the probability raster. 

# Brier: can't calculate because I need a probability prediction for each class... I could calculate this, but it would be fairly complicated to produce because I would need to use the raster which identifies which model each predicted cell came from, then extract the coresponding. This would involve to much computational overhead for the return I would get, but I think it would be super cool and probably show that the regional-ensemble would make much better predictions because looking at the probabilities they are much higher. 
#library(measures)
#all.max <-raster("Z:/UCRB/Predictions/all.max.tif")
#prob.valid <- raster::extract(all.max, v.dc3)
#eco3.es.bs <- multiclass.Brier(prob.valid, v.dc4$DepthClass)


# Ensemble model
# Shannon entropy
ses <- function(p) {
  sum(-p*log(p,base=length(p)), na.rm=TRUE)
}

# Non-spatial mean scaled entropy
MaxStack <- stack("Z:/UCRB/Predictions/MaxStack.tif")
prob.valid <- raster::extract(MaxStack, v.dc3)

# This doesn't make a lot of sense because the values no longer sum to one. That means that I can't do it for the spatial models as well.. Hmmm, time to get creative. How do I quantify uncertainty for predictions combined from multiple models? I guess that I could extract all the class probabilities from the class from which the final class prediction was taken (for each cell) because I would then be getting at the uncertainty for that prediction, but it seems that if I'm ensembling predictions I should figure out how to ensemble the uncertainty too. Instead I could also just say that this is an area that needs additional work and point out that possibly a method to weight models by environmental similatity might be a way forward because it would maybe make it possible to retain the distribution of each class... 
eco3.es.se <- mean(apply(prob.valid, 1, ses))

# Reading in the literature; most publications on ensemble modeling show methods to aggregate/average predictions with the understanding that each model is fit on the same data and so areas where the models agree (called concensus) (in SDM) are robust. However; in this study, because models were fit for specific geographic areas we cannot assume that ensemble modeling can be applied to the entire area carte-blanche. Instead, we are faced with the task of ensemble modeling with  models that should not be relevant in the entire area, but instead should be restricted (at least in theory) to different areas.

# This publication may be particularly important
#Overcoming limitations of modelling rare species by using ensembles of small models
#Overcoming the rare species modelling paradox: A novel hierarchical framework applied to an Iberian endemic plant

# These may also be relevant
#Uncertainty in ensemble forecasting of species distribution
#Evaluation of consensus methods in predictive species distribution modelling

#Ensemble distribution models in conservation prioritization: from consensus predictions to consensus reserve networks

# This is relevant for my biocrust paper: Ensemble modelling of species distribution: the effects of geographical and environmental ranges

# Relevant for individual class mapping? 
#BIOMOD - a platform for ensemble forecasting of species distribution (can only do binomial data, could I have a model for each taxonomic class - then ensemble models together?)
#How different are species distribution model predictions?-Application of a new measure of dissimilarity and level of significance to giant panda Ailuropoda melanoleuca
```

M2
Calculate spatial uncertainty (shannon's entropy spatially) for the regional models.  
Very interesting - shannon's entropy shows areas of overall uncertainty, even when the max prob for one class is relatively high. This seems to be because the other classes, although much lower, are relatively uncertain between themselves. For example (0.5, 0.1, 0.1, 0.1, 0.1, 0.1) has a surprisingly high entropy of 0.84, even though it is clear that the first class is dominate. Compare these values with the entropy from (0, .2, .2, .2, .2, .2) which is 0.89. It is clear that there is a lot of confusion in this second example. For this reason I think that the confusion index may still be worthwhile. 

Calculate only for ecoregions:
```{r}
# List physiographic probability prediction
#fp <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)_prob", full.names=T)
library(raster)

ses <- function(p) {
  sum(-p*log(p,base=length(p)), na.rm=TRUE)
}

# testing a few possible combinations of shannons entropy to understand the values
# testveryLow <- c(0,0,0,0,0,1)
# testLow <- c(.01,.01,.01,.01,.01,.95)
# testModerate <- c(0.5, 0.1, 0.1, 0.1, 0.1, 0.1)
# testHigh <- c(.1666, .1666, .1666, .1666, .1666, .167)
# 
# twoclassEqualProb   <- c(0,0,0,0, .5, .5)
# threeclassEqualProb <- c(0,0,0,.333, .333, .334)
# fourclassEqualProb  <- c(0,0,.25, .25, .25, .25)
# fiveclassEqualProb  <- c(0, .2, .2, .2, .2, .2)
# 
# ses(testveryLow)   # 0
# ses(testLow)       # 0.1557057
# ses(testModerate)  # 0.835975
# ses(testHigh)      # 0.9999998
# 
# 
# ses(twoclassEqualProb)   # 0.3868528
# ses(threeclassEqualProb) # 0.6131466
# ses(fourclassEqualProb)  # 0.7737056
# ses(fiveclassEqualProb)  # 0.8982444


# Calculate entropy
# each custerR takes about 7 min to run, so this should take about 1 hour to run
# beginCluster(32)
# p=6
# 
# # Entropy for the global model first. The code stopped failing if I hardcoded each stack. 
# M2.ses <- clusterR(stack("Z:/UCRB/Predictions/M2_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(M2.ses, "Z:/UCRB/Predictions/M2_ses.tif")
#  gc()
# 
# eco313.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco313_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco313.ses, "Z:/UCRB/Predictions/phy_area/eco313_ses.tif")
#  gc()
# 
# eco314.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco314_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco314.ses, "Z:/UCRB/Predictions/phy_area/eco314_ses.tif")
#  gc()
# 
# eco317.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco317_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco317.ses, "Z:/UCRB/Predictions/phy_area/eco317_ses.tif")
#  gc()
#   
# eco318.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco318_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco318.ses, "Z:/UCRB/Predictions/phy_area/eco318_ses.tif")
#  gc()
#   
# eco319.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco319_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco319.ses, "Z:/UCRB/Predictions/phy_area/eco319_ses.tif")
#  gc()
#   
# eco320.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco320_prob.tif"), calc, args=list(ses), export='p')
#  writeRaster(eco320.ses, "Z:/UCRB/Predictions/phy_area/eco320_ses.tif")
#  gc()
#   
# eco321.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco321_prob.tif"), calc, args=list(ses), export='p')
#   writeRaster(eco321.ses, "Z:/UCRB/Predictions/phy_area/eco321_ses.tif")
#   gc()
#   
# eco322.ses <- clusterR(stack("Z:/UCRB/Predictions/phy_area/eco322_prob.tif"), calc, args=list(ses), export='p')
#   writeRaster(eco322.ses, "Z:/UCRB/Predictions/phy_area/eco322_ses.tif")
#   gc()
# 
# endCluster()

```


M3. Combine regional probability predictions into a final map by clipping and joining. This works, but gives sharp boundaries and is what motivated me to look for another option. I chose ecoregion because it had the least uncertainty. 

Extract each polygon as it's own spatialpolygonsdataframe and buffer out
```{r}
library(rgdal)
library(raster)
library(dplyr)
rasterOptions(timer = TRUE)

eco3.b <- readOGR(dsn="Z:/UCRB/Boundaries", layer = "CO_River_watershed_Meade_NAD83_EcoL3_dissolve")

polyList <- list()
for(i in levels(eco3.b@data$US_L3CODE)) {
  polyList[[i]] <- eco3.b[eco3.b@data$US_L3CODE == i,]
}


# buffer each region by 1 km
polyBuff <- llply(polyList, .fun = buffer, width=1000)
```

Clip each prediction and uncertainty. Always use the regional prediction. Although I could use the global where it is better than the regional, after some consideration I discovered that for 4 of the 8 regions the regional model accuracy, Brier, and Entropy were all better than the global model. For the other 4 regions, the differences between regional and global were less clear, but I chose to use the regional as the entropy was generally lower for the regional models for these three regions. It is also cleaner just to use the regional models

```{r}
library(purrr)
# Get file names for the class (fpc) and the entropy (fps) predictions
fpc <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)[^_prob][^_ses_max].tif", full.names=T)

fps <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)_ses", full.names=T)

fpm <- list.files(path = "Z:/UCRB/Predictions/phy_area", pattern = "eco3(.*)_max", full.names=T)


# Make a list of each raster
rsList <- map(fpc, raster)
rsLists<- map(fps, raster)
rsListMax <- map(fpm, raster)

# DO I EVEN NEED TO MASK?
# # Mask prediction and write to file
# for(i in seq_along(rsList)) {
#   raster::mask(rsList[[i]], polyBuff[[i]], filename = paste0("Z:/UCRB/Predictions/phy_area/eco3", names(polyBuff[i]),"_m", ".tif"))
# }
# 
# for(i in seq_along(rsLists)) {
#   mask(rsLists[[i]], polyBuff[[i]], filename = paste0("Z:/UCRB/Predictions/phy_area/eco3", names(polyBuff)[i],"_ses_m", ".tif"))
# }

# NOT YET RUN
# for(i in seq_along(rsListMax)) {
#   mask(rsListMax[[i]], polyBuff[[i]], filename = paste0("Z:/UCRB/Predictions/phy_area/eco3", names(polyBuff)[i],"_max_m", ".tif"))
# }

#time 5.8 hours
#(638+ 310+ 1242+ 306+ 292+ 312+ 1875+ 301+ 724+ 308+ 5751+ 319+ 2547+ 313+ 5441+ 301)/3600

#cbind(as.character(eco3.b$US_L3CODE), as.character(eco3.b@data$US_L3NAME))
#"13" "Central Basin and Range" 
#"14" "Mojave Basin and Range" 
#"17" "Middle Rockies" 
#"18" "Wyoming Basin" 
#"19" "Wasatch and Uinta Mountains" 
#"20" "Colorado Plateaus" 
#"21" "Southern Rockies" 
#"22" "Arizona/New Mexico Plateau" 

# This took longer to run than just doing it serially.
# Set up parallel backend
# library(foreach)
# library(doSNOW)
# library(iterators)
# 
# cl <- makeCluster(detectCores() - 2)
# registerDoParallel(cl)
# 
# foreach(i=seq_along(rsList)) %dopar% {
#   raster::mask(rsList[[i]], polyBuff[[i]], filename = paste0("Z:/UCRB/Predictions/phy_area/eco3", names(polyBuff[[i]]),"_m", ".tif"))
# }
# stopCluster(cl)
```


Mosaic. The following script  is how you do this in gdal + sagagis to use feathering. A bad idea. 
@ECHO OFF
REM File to mosiac soil depth predictions back together. Open OsGeo4W navigate to file and run. 
REM https://stackoverflow.com/questions/4813273/dir-b-command-output-in-one-line-with-delimiter-added-batch-file-programming
REM options http://www.saga-gis.org/saga_tool_doc/6.3.0/grid_tools_3.html
REM RESAMPLING = 9: nearest neighbor for categorical data, otherwise use 2: bicubic spline
REM OVERLAP = 6; feathering
REM -BLEND_DIST: blending distance given in map units. Since I overlapped by 1000 m, then I want a 1000 m blend distance
REM -TARGET_USER_SIZE=30.0 (cell size, 30.0 = 30.0 meters)

REM I really need to do this in R, but this is fairly straight forward
REM path to saga_cmd.exe
set PATH=%PATH%;C:\saga-6.2.0_x64
set SAGA_MLB=C:\saga-6.2.0_x64\tools

set desFol=Z:\UCRB\Predictions\phy_area

REM Entropy (ses)
setlocal enabledelayedexpansion enableextensions
set LIST=
	for /f %%x in ('dir /b /s *_ses_m.tif') do set LIST=!LIST!;%%x
	saga_cmd grid_tools 3 -GRIDS=%LIST:~1% -TARGET_OUT_GRID=%desFol%ucrb_regional_ses.sgrd -TYPE=9 -RESAMPLING=2 -OVERLAP=6 -BLEND_DIST=1000 -TARGET_USER_SIZE=30.0
	gdalwarp -co COMPRESS=DEFLATE -co TILED=YES  %desFol%/ucrb_regional_ses.sdat %desFol%/ucrb_regional_ses.tif
	

REM predictions
setlocal enabledelayedexpansion enableextensions
set LIST=
	for /f %%x in ('dir /b /s eco3??_m.tif') do set LIST=!LIST!;%%x
	saga_cmd grid_tools 3 -GRIDS=%LIST:~1% -TARGET_OUT_GRID=%desFol%ucrb_regional_pred.sgrd -TYPE=9 -RESAMPLING=0 -OVERLAP=6 -BLEND_DIST=1000 -TARGET_USER_SIZE=30.0
	gdalwarp -co COMPRESS=DEFLATE -co TILED=YES  %desFol%/ucrb_regional_pred.sdat %desFol%/ucrb_regional_pred.tif
	


M4 Cross Validation
These plots show that there is more variation in the cross validation when splitting by region than for the global models. This is because there are fewer observations in each region. These plots also show that there are generally some regions higher and some lower than the global model.
```{r}
# Physiographic areas
#mlra
mlra.cv <- resamples(list(global=M1, 
                          global_nlc=M2,
                          mlra_35 = c.mlra[[1]],
                          mlra_38 = c.mlra[[2]],
                          mlra_43 = c.mlra[[3]],
                          mlra_44 = c.mlra[[4]],
                          mlra_45 = c.mlra[[5]],
                          mlra_46 = c.mlra[[6]],
                          mlra_60 = c.mlra[[7]],
                          mlra_64 = c.mlra[[8]],
                          mlra_65 = c.mlra[[9]]))

#ecoregions
eco3.cv <- resamples(list(global= M1, 
                          global_nlc = M2,
                          ecoregion_13 = c.eco3[[1]],
                          ecoregion_14 = c.eco3[[2]],
                          ecoregion_17 = c.eco3[[3]],
                          ecoregion_18 = c.eco3[[4]],
                          ecoregion_19 = c.eco3[[5]],
                          ecoregion_20 = c.eco3[[6]],
                          ecoregion_21 = c.eco3[[7]],
                          ecoregion_22 = c.eco3[[8]]))


#landform
ilf.cv <- resamples(list(global= M1, 
                         global_nlc = M2,
                         Iwahashi_1 = c.iwlf[[1]],
                         Iwahashi_2 = c.iwlf[[2]],
                         Iwahashi_3 = c.iwlf[[3]],
                         Iwahashi_4 = c.iwlf[[4]]))



# Geographic areas
#4 areas
g4.cv <- resamples(list(global=M1, 
                        global_nlc=M2,
                        geo_0 = c.g4[[1]],
                        geo_1 = c.g4[[2]],
                        geo_2 = c.g4[[3]],
                        geo_3 = c.g4[[4]]))

#8 areas
g8.cv <- resamples(list(global=M1, 
                        global_nlc=M2,
                        geo_0 = c.g8[[1]],
                        geo_1 = c.g8[[2]],
                        geo_2 = c.g8[[3]],
                        geo_3 = c.g8[[4]],
                        geo_4 = c.g8[[5]],
                        geo_5 = c.g8[[6]],
                        geo_6 = c.g8[[7]],
                        geo_7 = c.g8[[8]]))

#9 areas
g9.cv <- resamples(list(global=M1, 
                        global_nlc=M2,
                        geo_0 = c.g9[[1]],
                        geo_1 = c.g9[[2]],
                        geo_2 = c.g9[[3]],
                        geo_3 = c.g9[[4]],
                        geo_4 = c.g9[[5]],
                        geo_5 = c.g9[[6]],
                        geo_6 = c.g9[[7]],
                        geo_7 = c.g9[[8]],
                        geo_8 = c.g9[[9]]))


bwplot(mlra.cv, metric='Accuracy')
bwplot(eco3.cv, metric='Accuracy')
bwplot(ilf.cv, metric='Accuracy')

bwplot(g4.cv, metric='Accuracy')
bwplot(g8.cv, metric='Accuracy')
bwplot(g9.cv, metric='Accuracy')
```

Kappa
```{r}
# Validation Kappa
# Rossiters' "Technical Note: Statistical methods for accuracy assesment of classified thematic maps" indicates that kappa is best when we know the marginal probabilities. We don't know this, so Kappa is not a great estimate of accuracy. Instead, use Tau. Except that I don't have time to code for Tau right now.

# Physiographic areas
# MLRA
mlra.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="MLRA", x = "Kappa") +
  ylim(0.1, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_MLRA.png", height=3, width=5)

# Ecoregion
eco3.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="Ecoregion", x = "Kappa") + 
  ylim(0.1, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_eco3.png", height=3, width=5)

# Landform
ilf.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="Landform", x = "Kappa") + 
  ylim(0.1, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_iwlf.png", height=3, width=5)


# Geographic areas
# 9 areas
g9.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="9 geographic areas", x = "Kappa") + 
  ylim(0.1, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_geo9.png", height=3, width=3)

# 8 areas
g8.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="8 geographic area", x = "Kappa") + 
  ylim(0.2, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_geo8.png", height=3, width=3)

# 4 areas
g4.acc %>%
  mutate(.id = fct_reorder(.id, Kappa)) %>%
  ggplot(aes(x=.id, y=Kappa)) +
  geom_point(size = 2.5) +
  labs(x="4 geographic areas", x = "Kappa") +
  ylim(0.2, 0.7) +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/ValidationKappa_geo4.png", height=3, width=3)


# If I want to add overall global model accuracy to each data frame
# First create a dataframe that matches the structure I want to join to
 # gmod  <- data.frame('.id' = c('Global1', 'Global2'))
 # gmod1 <- cbind(gmod, rbind(M1.cm$overall, M2.cm$overall))
```


M5 Make predictions for global model (have to set up covariate stack to match model predictors)
Make predictions using the model with the land class covariates. This turned out to be a bad idea because the model decomposes each land class into a dummy variable so I have to create dummy variables from the land class covariates and that seems like a lot of overhead. 
```{r}
#Code  is not complete

# To make predictions using the categorical land classification covariates I have to create rasters for each factor level because the M1 model split each factor level of the MLRA, Eco3, and Iwlf covariates into a separate variable.

#THis almost works, well actually it does, but I combined several of the mlras and other land classes so that I will need to collapse these dummy variables. Why are there < 4 iwahashi landform classes? 

mlra.lev <- layerize(raster("Z:/UCRB/Covariates/LandClassCovariates/mlra_UCRB_m.tif"), falseNA = TRUE, filename = "Z:/UCRB/Covariates/DummyVariables/mlra_UCRB_m_dummy.tif")
names(mlra.lev) <- c("mlra_UCRB_m38", "mlra_UCRB_m43", "mlra_UCRB_m44", "mlra_UCRB_m45", "mlra_UCRB_m46", "mlra_UCRB_m60", "mlra_UCRB_m64", "mlra_UCRB_m65") 
#The names are the predictors from the model predictors(M1), but which classes did I collapse?


eco3.lev <- layerize(raster("Z:/UCRB/Covariates/LandClassCovariates/us_eco_l3_m.tif"), falseNA = TRUE, filename = "Z:/UCRB/Covariates/DummyVariables/us_eco_l3_m_dummy.tif")
#"us_eco_l3_m14"      "us_eco_l3_m17"      "us_eco_l3_m18"      "us_eco_l3_m19"     "us_eco_l3_m20"      "us_eco_l3_m21"      "us_eco_l3_m22"           


iwlf.lev <- layerize(raster("Z:/UCRB/Covariates/TravisCovariates/iwahashiLF_m.tif"), falseNA = TRUE, filename = "Z:/UCRB/Covariates/DummyVariables/iwahashiLF_dummy.tif")
# "iwahashiLF_m2"     "iwahashiLF_m3"      "iwahashiLF_m4"   

# Add land class dummy covariates to raster stack
Mpred.lc <- stack(Mpred, mlra.lev, eco3.lev, iwlf.lev)

#5.2.2 This will work once I have all the variables in the model as covariates, but do I even need to do this? The model without landclass covariates is easier and usually more accurate.

rasterOptions(maxmemory = 1e+9, chunksize = 1e+7, timer = TRUE)
Sys.time()
beginCluster()




# Did not run this code because I decided that I only needed the probability layer right now. 
#raster::predict(object=Mpred1, model=M2, progress="text", filename = 'Z:/UCRB/Predictions/M1.tif', datatype = 'INT1U', options=c("COMPRESS=LZW"))

raster::predict(object=Mpred1, model=M1, index = 1:6, type = 'prob', progress="text", filename = 'Z:/UCRB/Predictions/M1_prob.tif', datatype = 'FLT4S', options=c("COMPRESS=LZW"))

endCluster()
Sys.time()
```


M6. LogLoss instead of accuracy as metric to minimize when training. 
This didn't seem to make much difference, it decreased accuracy of BR and increased VD sliglyt, but decreased VS specificity about 6%. 
```{r}
llControl <- trainControl(method = "cv", 
                           savePredictions = T, 
                           returnResamp = 'final',
                           allowParallel = TRUE,
                           classProbs=TRUE,
                           selectionFunction='oneSE',
                           summaryFunction=mnLogLoss)


cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
llMod = train(DepthClass ~ ., 
           data = t.dc3[-c(2:4)], 
           method="rf", 
           metric='logLoss',
           trControl = llControl, 
           tuneGrid=tunegrid)
stopCluster(cl)
llMod


ll.pred <- predict(llMod, newdata = v.dc4)
ll.cm <- confusionMatrix(data=ll.pred, reference = v.dc4$DepthClass)
```



M7. Rebuild models with all obs to make predictions as accurate as possible
Split the all of the observation data by area so that I can use it to model 
```{r}
obs3.mlra <- split(obs3[,-c(2:7,9:10)], f = obs3$mlra_UCRB_m)
obs3.eco3 <- split(obs3[,-c(2:7,9:10)], f = obs3$us_eco_l3_m)
obs3.iwlf <- split(obs3[,-c(2:7,9:10)], f = obs3$iwahashiLF_m)
```

Rebuild models
Global model
```{r}
# Set up parallization
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
M2.allobs = train(DepthClass ~ ., data = obs3[,-c(2:10)], method="rf", trControl = fitControl, tuneGrid=tunegrid)
stopCluster(cl)
M2.allobs
```

MLRA
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
mlra.all.obs <- llply(obs3.mlra, region.train)
stopCluster(cl)

c.mlra
mlra.all.obs
```

Ecoregion
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
eco3.all.obs <- llply(obs3.eco3, region.train)
stopCluster(cl)

c.eco3
eco3.all.obs
```

By broad landform (iwahashi)
```{r, include=FALSE}
cl <- makePSOCKcluster(30)
registerDoParallel(cl)
set.seed(4801)
iwlf.all.obs <- llply(obs3.iwlf, region.train)
stopCluster(cl)

c.iwlf
iwlf.all.obs
```

Review Cross validation
```{r}
mlra.cv <- resamples(list(
  "Global"                                      = M2.allobs, 
  "Great Salt Lake Area"                        = mlra.all.obs[[1]],
  "Mojave Desert"                               = mlra.all.obs[[2]],
  'Cool Central Desertic Basins and Plateaus'   = mlra.all.obs[[3]],
  'Warm Central Desertic Basins and Plateaus'   = mlra.all.obs[[4]],
  'Colorado Plateau'                            = mlra.all.obs[[5]],
  'Southwestern Plateaus, Mesas, and Foothills' = mlra.all.obs[[6]],
  'Central Rocky Mountains'                     = mlra.all.obs[[7]],
  'Wasatch and Uinta Mountains'                 = mlra.all.obs[[8]],
  'Southern Rocky Mountains'                    = mlra.all.obs[[9]]))

# Manually compare this plot with the MLRA plot build using a seperate training/test set. This comparision reveals that CV accuracies are surpisingly different from validation accuracies. The CV accuraties are surpisingly often lower than validaiton accuracies 
bwplot(mlra.cv, metric='Accuracy')
```


M8 Calculate MESS - MESS is not working. Mask all regional prediction using MESS to limit to appropriate areas, all other areas = NA - I should do this, but it is difficult because MESS is giving me weird results
```{r}
library(raster)
library(dismo)
# I have to use the subset command for v so that I can remove the depthclass and mlra columns, which are included in the training data (the mlra is not included in the model), but not in the raster stack. This takes 8.7 hours
Sys.time()
mess.35 <- mess(x=Mpred1, v=subset(t.mlra[[1]], select=-c(DepthClass, mlra_UCRB_m)), full = TRUE)
writeRaster(mess.35, "Z:/UCRB/mess35.tif")


mess.35 <- stack("Z:/UCRB/mess35.tif")

Sys.time() # about 5 hours
mess.35.m <- reclassify(mess.35, cbind(-Inf, 0, NA), right=FALSE) # about 2 min
writeRaster(mess.35.m, "Z:/UCRB/mess35_mask.tif")

#library(rasterVis)
#levelplot(mess.35.m)


# predictions


```


M9. Variable importance 
```{r}
# Variable importance as a dataframe
M1.varimp <- varImp(M1)
M2.varimp <- varImp(M2)
mlra.varimp <- llply(c.mlra, function (x) as.data.frame(varImp(x)$importance))
eco3.varimp <- llply(c.eco3, function (x) as.data.frame(varImp(x)$importance))
iwlf.varimp <- llply(c.iwlf, function (x) as.data.frame(varImp(x)$importance))


# Exceptionally Inelegant way to rename covariate names for better plotting
rownames(M1.varimp$importance) <- recode(rownames(M1.varimp$importance),
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature", 
"LFELEMS_m" = "Landform elements")


for (i in seq(mlra.varimp)) {
rownames(mlra.varimp[[i]]) <- recode(rownames(mlra.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature", 
"LFELEMS_m" = "Landform elements")
}

for (i in seq(eco3.varimp)) {
rownames(eco3.varimp[[i]]) <- recode(rownames(eco3.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature", 
"LFELEMS_m" = "Landform elements")
}

for (i in seq(iwlf.varimp)) {
rownames(iwlf.varimp[[i]]) <- recode(rownames(iwlf.varimp[[i]]), 
"ppt_ann_rs_m"= "Annual precipitation",
"temp_ann_rs_m"= "Annual temperature",
"TIR_med_m"= "Brightness temperature 3 year median",
"TIR_std_m"= "Brightness temperature 3 year standard deviation",
"ca_mosaic_m"= "Catchment area",
"cs_mosaic_m"= "Catchment slope",
"L57_med_m"= "Clay normalized ratio 3 year median",
"ci_mosaic_m"= "Convergence index",
"cc_mosaic_m"= "Cross-sectional curvature",
"dah_mosaic_m"= "Diurnal anisotropic heating",
"EASTNESS_rs_m"= "Eastness",
"ELEVm_m"= "Elevation",
"L54_med_m"= "Ferrous normalized ratio 3 year median",
"gammaAbsbDose_m"= "Gamma radiometrics absorbed dose",
"gammaPotassium_m"= "Gamma radiometrics potassium",
"gammaThorium_m"= "Gamma radiometrics thorium",
"gammaUranium_m"= "Gamma radiometrics uranium",
"gmph_mosaic_m"= "Geomorphons",
"LFELEMS_m"= "Landform elements",
"lc_mosaic_m"= "Longitudinal curvature",
"mbi_mosaic_m"= "Mass balance index",
"mc_mosaic_m"= "Minimum curvature",
"mca_mosaic_m"= "Modified catchment index",
"mrrtf_mosaic_m"= "Multi-resolution ridge top flatness",
"mrvbf_mosaic_m"= "Multi-resolution valley bottom flatness",
"L43_med_m"= "NDVI 3 year median",
"L43_std_m"= "NDVI 3 year std deviation",
"L51_med_m"= "Normalized ratio SWIR/blue",
"NENESS_rs_m"= "Northeastness",
"NWNESS_rs_m"= "Northwestness",
"SDT"= "Pelletier soil thickness",
"planc_mosaic_m"= "Plan curvature",
"po_mosaic_m"= "Positive openess",
"ppt_ratio_rs_m"= "Precipitation ratio",
"profc_mosaic_m"= "Profile curvature",
"PROTINDEX_rs_m"= "Protection index",
"RELHT1_rs_m"= "Relative height",
"RELHT128_rs_m"= "Relative height 128 cell radius",
"RELHT16_rs_m"= "Relative height 16 cell radius",
"RELHT2_rs_m"= "Relative height 2 cell radius",
"RELHT32_rs_m"= "Relative height 32 cell radius",
"RELHT4_rs_m"= "Relative height 4 cell radius",
"RELHT64_rs_m"= "Relative height 64 cell radius",
"RELHT8_rs_m"= "Relative height 8 cell radius",
"RELMNHT1_rs_m"= "Relative mean height",
"RELMNHT128_rs_m"= "Relative mean height 128 cell radius",
"RELMNHT16_rs_m"= "Relative mean height 16 cell radius",
"RELMNHT2_rs_m"= "Relative mean height 2 cell radius",
"RELMNHT32_rs_m"= "Relative mean height 32 cell radius",
"RELMNHT64_rs_m"= "Relative mean height 64 cell radius",
"RELMNHT8_rs_m"= "Relative mean height 8 cell radius",
"swi_mosaic_m"= "Saga wetness index",
"sl_mosaic_m"= "Slope",
"BDTICM_M_250m_ll_m"= "SoilGrids250m absolute depth to bedrock",
"BDRICM_M_250m_ll_m"= "SoilGrids250m depth to bedrock",
"BDRLOG_M_250m_ll_m"= "SoilGrids250m probability of occurrence of R horizon",
"SOUTHNESS_rs_m"= "Southness",
"spi_mosaic_m"= "Stream power index",
"tsc_mosaic_m"= "Terrain surface convexity",
"tpi_mosaic_m"= "Topographic position index",
"tri_mosaic_m"= "Topographic ruggedness index",
"twi_mosaic_m"= "Topographic wetness index",
"tc_mosaic_m"= "Total curvature", 
"LFELEMS_m" = "Landform elements")
}

# Give better names for plotting. This works because I preserved the order of list elements. 
names(mlra.varimp) <- c( 
"Great Salt Lake Area",  
"Mojave Desert",
'Cool Central Desertic Basins and Plateaus',
'Warm Central Desertic Basins and Plateaus',
'Colorado Plateau',
'Southwestern Plateaus, Mesas, and Foothills',
'Central Rocky Mountains',
'Wasatch and Uinta Mountains',
'Southern Rocky Mountains')

names(eco3.varimp) <- c(
'Central Basin and Range',
'Mojave Basin and Range',
'Middle Rockies',
'Wyoming Basin',
'Wasatch and Uinta Mountains',
'Colorado Plateaus',
'Southern Rockies',
'Arizona and New Mexico Plateau')

names(iwlf.varimp) <- c(
'Bedrock mountain',
'Hills',
'Large highland slope',
'Plateau, terrace, large lowland slope, plains')


# Plot variable importance for each model
# M1
M1.varimp$importance %>%
as.data.frame() %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
 ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
  ggtitle('Global Model') +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/varimp_Global.png", height=1.75, width=4)

# M2 - pretty much the same as M1
M2.varimp$importance %>%
as.data.frame() %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
 ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
  ggtitle('Global Model nlc') +
  coord_flip() + 
  theme_bw()
ggsave("Z:/UCRB/Figures/varimp_Global_nlc.png", height=1.75, width=4)

#MLRA
for (i in 1:length(mlra.varimp)){
mlra.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(mlra.varimp)[i]) +
    coord_flip() + 
  theme_bw()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','mlra_', names(mlra.varimp)[i], ".png"),  height=1.75, width=6)
}


#Ecoregion
for (i in 1:length(eco3.varimp)){
eco3.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(eco3.varimp)[i]) +
    coord_flip() + 
  theme_bw()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','eco3_', names(eco3.varimp)[i], ".png"),  height=1.75, width=6)
}


#Landform
for (i in 1:length(iwlf.varimp)){
iwlf.varimp[[i]] %>%
tibble::rownames_to_column() %>%
dplyr::arrange(-Overall)  %>%
{`[`(.[1:5,])} %>%
ggplot(aes(x = reorder(rowname, Overall), y = Overall)) +
  geom_bar(stat = "identity", fill = "#1F77B4", alpha = 0.8) +
  xlab('Covariate') +
    ggtitle(names(iwlf.varimp)[i]) +
    coord_flip() + 
  theme_bw()
ggsave(paste0("Z:/UCRB/Figures/", 'varimp_','iwlf_', names(iwlf.varimp)[i], ".png"),  height=1.75, width=6)
}
```








```

